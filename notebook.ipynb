{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.utils import class_weight\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import roc_auc_score, f1_score, hamming_loss, precision_score, recall_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3T3rC7IbTlDN"
   },
   "source": [
    "# Nettoyage, Tokenisation et Préparation des Embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySf6LBRnVvtH",
    "outputId": "fe2f287b-93bd-4a3d-a4f5-1fcb36281b30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de données d'entraînement : 43410 lignes\n",
      "Jeu de données de validation : 5426 lignes\n",
      "Jeu de données de test : 5427 lignes\n",
      "\n",
      "Aperçu de la colonne des IDs avant transformation :\n",
      "0    27\n",
      "1    27\n",
      "2     2\n",
      "3    14\n",
      "4     3\n",
      "Name: emotion_ids, dtype: object\n",
      "\n",
      "Aperçu du DataFrame d'entraînement FINAL :\n",
      "                                                text comment_id  admiration  \\\n",
      "0  My favourite food is anything I didn't have to...    eebbqej           0   \n",
      "1  Now if he does off himself, everyone will thin...    ed00q6i           0   \n",
      "2                     WHY THE FUCK IS BAYLESS ISOING    eezlygj           0   \n",
      "3                        To make her feel threatened    ed7ypvh           0   \n",
      "4                             Dirty Southern Wankers    ed0bdzj           0   \n",
      "\n",
      "   amusement  anger  annoyance  approval  caring  confusion  curiosity  ...  \\\n",
      "0          0      0          0         0       0          0          0  ...   \n",
      "1          0      0          0         0       0          0          0  ...   \n",
      "2          0      1          0         0       0          0          0  ...   \n",
      "3          0      0          0         0       0          0          0  ...   \n",
      "4          0      0          1         0       0          0          0  ...   \n",
      "\n",
      "   love  nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n",
      "0     0            0         0      0            0       0        0        0   \n",
      "1     0            0         0      0            0       0        0        0   \n",
      "2     0            0         0      0            0       0        0        0   \n",
      "3     0            0         0      0            0       0        0        0   \n",
      "4     0            0         0      0            0       0        0        0   \n",
      "\n",
      "   surprise  neutral  \n",
      "0         0        1  \n",
      "1         0        1  \n",
      "2         0        0  \n",
      "3         0        0  \n",
      "4         0        0  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "La taille du X_train (après padding) est : (43410, 70)\n",
      "La taille du Y_train est : (43410, 28)\n"
     ]
    }
   ],
   "source": [
    "EMOTION_LABELS = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
    "    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
    "    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude',\n",
    "    'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride',\n",
    "    'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]\n",
    "NUM_LABELS = len(EMOTION_LABELS)\n",
    "\n",
    "# 3. Noms des colonnes pour les TSV (Pas de header, séparateur Tab)\n",
    "COLUMN_NAMES = ['text', 'emotion_ids', 'comment_id']\n",
    "tsv_path = 'dataset/data/'\n",
    "df_train = pd.read_csv(os.path.join(tsv_path, 'train.tsv'), sep='\\t', header=None, names=COLUMN_NAMES, encoding='utf-8')\n",
    "df_dev = pd.read_csv(os.path.join(tsv_path, 'dev.tsv'), sep='\\t', header=None, names=COLUMN_NAMES, encoding='utf-8')\n",
    "df_test = pd.read_csv(os.path.join(tsv_path, 'test.tsv'), sep='\\t', header=None, names=COLUMN_NAMES, encoding='utf-8')\n",
    "\n",
    "print(f\"Jeu de données d'entraînement : {len(df_train)} lignes\")\n",
    "print(f\"Jeu de données de validation : {len(df_dev)} lignes\")\n",
    "print(f\"Jeu de données de test : {len(df_test)} lignes\")\n",
    "\n",
    "# Vérification (doit contenir des chaînes d'IDs comme '2' ou '1,17')\n",
    "print(\"\\nAperçu de la colonne des IDs avant transformation :\")\n",
    "print(df_train['emotion_ids'].head())\n",
    "\n",
    "def create_binary_labels(df, labels_list):\n",
    "    \"\"\"\n",
    "    Convertit la colonne 'emotion_ids' (chaîne d'IDs séparées par des virgules)\n",
    "    en 28 colonnes binaires (0 ou 1) pour la classification multi-label.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialise un DataFrame binaire vide de taille (Nb_lignes x 28)\n",
    "    label_matrix = pd.DataFrame(0, index=df.index, columns=labels_list)\n",
    "\n",
    "    # Parcourt chaque ligne du DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Sépare les IDs d'émotions (sont des chaînes, ex: '2,5' -> ['2', '5'])\n",
    "        ids = str(row['emotion_ids']).split(',')\n",
    "\n",
    "        # Convertit les IDs en entiers pour les utiliser comme index\n",
    "        # L'index 0 correspond à la première émotion de votre liste, etc.\n",
    "        try:\n",
    "            # S'assure de ne traiter que des IDs valides (chiffres)\n",
    "            int_ids = [int(i) for i in ids if i.isdigit()]\n",
    "        except ValueError:\n",
    "            # Cas d'erreur (rare) ou ID non numérique\n",
    "            int_ids = []\n",
    "\n",
    "        # Met à 1 les colonnes correspondantes dans la matrice\n",
    "        for emotion_index in int_ids:\n",
    "            # S'assurer que l'index est valide (entre 0 et 27)\n",
    "            if 0 <= emotion_index < NUM_LABELS:\n",
    "                label_matrix.loc[index, labels_list[emotion_index]] = 1\n",
    "\n",
    "    # Concatène le DataFrame binaire avec le DataFrame original\n",
    "    df_result = pd.concat([df[['text', 'comment_id']], label_matrix], axis=1)\n",
    "\n",
    "    return df_result\n",
    "\n",
    "# Appliquer la transformation aux trois DataFrames\n",
    "df_train_final = create_binary_labels(df_train, EMOTION_LABELS)\n",
    "df_dev_final = create_binary_labels(df_dev, EMOTION_LABELS)\n",
    "df_test_final = create_binary_labels(df_test, EMOTION_LABELS)\n",
    "\n",
    "print(\"\\nAperçu du DataFrame d'entraînement FINAL :\")\n",
    "print(df_train_final.head())\n",
    "\n",
    "# 1. Définir les hyperparamètres (à ajuster)\n",
    "\n",
    "MAX_WORDS = 50000    # Taille maximale du vocabulaire (les 20000 mots les plus fréquents)\n",
    "MAX_LEN = 70         # Longueur maximale d'une séquence (un commentaire)\n",
    "\n",
    "# 2. Instancier et adapter le Tokenizer UNIQUEMENT sur les données d'ENTRAÎNEMENT\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(df_train_final['text'])\n",
    "\n",
    "# 3. Transformer les textes en séquences d'entiers (indices de mots)\n",
    "train_sequences = tokenizer.texts_to_sequences(df_train_final['text'])\n",
    "dev_sequences = tokenizer.texts_to_sequences(df_dev_final['text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(df_test_final['text'])\n",
    "\n",
    "# 4. Padding (uniformisation de la longueur des séquences)\n",
    "# Remplissage à MAX_LEN (ajout de zéros au début ou à la fin)\n",
    "X_train = pad_sequences(train_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "X_dev = pad_sequences(dev_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "X_test = pad_sequences(test_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "print(f\"La taille du X_train (après padding) est : {X_train.shape}\")\n",
    "Y_train = df_train_final[EMOTION_LABELS].values\n",
    "Y_dev = df_dev_final[EMOTION_LABELS].values\n",
    "Y_test = df_test_final[EMOTION_LABELS].values\n",
    "\n",
    "print(f\"La taille du Y_train est : {Y_train.shape}\") # Devrait être (Nb_lignes, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_dict = {}\n",
    "for i in range(NUM_LABELS):\n",
    "    y_col = Y_train[:, i]\n",
    "    try:\n",
    "        weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_col),\n",
    "            y=y_col\n",
    "        )\n",
    "        class_weights_dict[i] = weights[1]\n",
    "    except ValueError:\n",
    "        class_weights_dict[i] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdWjzCgkWKTr"
   },
   "source": [
    "# LSTM AVEC EMBEDDING APPRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "QCO6Ah1vXoQq",
    "outputId": "4fd13086-ac7f-43b5-dfef-811312f68b3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SEQUENTIAL ET MODEL_LSTM \n",
    "# 1. Création du modèle séquentiel\n",
    "model_lstm = Sequential()\n",
    "# 2. Couche Embedding (Option A : Apprentissage des poid\n",
    "# Cette couche transforme les indices de mots (X_train) en vecteurs denses.\n",
    "model_lstm.add(Embedding(\n",
    "    input_dim=MAX_WORDS,\n",
    "    output_dim=100,\n",
    "    input_length=MAX_LEN\n",
    "))\n",
    "model_lstm.add(Dropout(0.2))  # ✅ AJOUT: Dropout après embedding\n",
    "\n",
    "# 3. Couche LSTM (Réseau de neurones récurrents)# C'est le cœur du modèle, il lit la séquence et capture les dépendances.\n",
    "# - units: Nombre de neurones/unités internes\n",
    "model_lstm.add(LSTM(units=128))\n",
    "model_lstm.add(Dropout(0.5))  # ✅ AJOUT: Dropout avant la couche Dense\n",
    "\n",
    "# Note: On n'utilise pas return_sequences=True ici car nous voulons un seul vecteur\n",
    "# de sortie pour toute la séquence, nécessaire pour la classification finale.\n",
    "# 4. Couche de Classification Finale units: Doit être égal au nombre de classes (28) et activation: 'sigmoid' .\n",
    "#   Chaque neurone de sortie prédit indépendamment la probabilité d'une émotion.\n",
    "model_lstm.add(Dense(NUM_LABELS, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# 2. COMPILATION \n",
    "\n",
    "# Définition de l'optimiseur (Adam est un bon choix par défaut)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# Compilation\n",
    "model_lstm.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy', # ESSENTIEL pour le multi-label\n",
    "    metrics=[   \n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DE9nCDBBYfc_",
    "outputId": "15f904cf-a7ec-4d11-fb0b-5e01159e5e99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DÉBUT DE L'ENTRAÎNEMENT DU LSTM SIMPLE ---\n",
      "Epoch 1/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 469ms/step - accuracy: 0.1041 - auc: 0.5909 - loss: 2.1590 - val_accuracy: 0.2934 - val_auc: 0.7103 - val_loss: 0.1654\n",
      "Epoch 2/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 688ms/step - accuracy: 0.1716 - auc: 0.6319 - loss: 2.0194 - val_accuracy: 0.2934 - val_auc: 0.6737 - val_loss: 0.1668\n",
      "Epoch 3/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 385ms/step - accuracy: 0.2223 - auc: 0.6426 - loss: 2.0128 - val_accuracy: 0.2934 - val_auc: 0.7091 - val_loss: 0.1648\n",
      "Epoch 4/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 274ms/step - accuracy: 0.2618 - auc: 0.6523 - loss: 2.0045 - val_accuracy: 0.2934 - val_auc: 0.6747 - val_loss: 0.1659\n",
      "Epoch 5/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 130ms/step - accuracy: 0.2590 - auc: 0.6526 - loss: 2.0001 - val_accuracy: 0.2934 - val_auc: 0.7153 - val_loss: 0.1636\n",
      "Epoch 6/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 136ms/step - accuracy: 0.2735 - auc: 0.6578 - loss: 1.9999 - val_accuracy: 0.2934 - val_auc: 0.7301 - val_loss: 0.1631\n",
      "Epoch 7/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 148ms/step - accuracy: 0.2828 - auc: 0.6615 - loss: 1.9968 - val_accuracy: 0.2934 - val_auc: 0.7052 - val_loss: 0.1662\n",
      "Epoch 8/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 154ms/step - accuracy: 0.2876 - auc: 0.6602 - loss: 1.9963 - val_accuracy: 0.2934 - val_auc: 0.6787 - val_loss: 0.1653\n",
      "Epoch 9/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 225ms/step - accuracy: 0.2868 - auc: 0.6598 - loss: 1.9988 - val_accuracy: 0.2934 - val_auc: 0.7343 - val_loss: 0.1639\n",
      "Epoch 10/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 226ms/step - accuracy: 0.2896 - auc: 0.6619 - loss: 1.9941 - val_accuracy: 0.2934 - val_auc: 0.7167 - val_loss: 0.1643\n",
      "\n",
      "--- ENTRAÎNEMENT TERMINÉ ---\n"
     ]
    }
   ],
   "source": [
    "# 3- FIT AVEC EPOCHS / BATCH SIZE\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "print(\"\\n--- DÉBUT DE L'ENTRAÎNEMENT DU LSTM SIMPLE ---\")\n",
    "\n",
    "lstm_simple = model_lstm.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_dev, Y_dev),\n",
    "        class_weight=class_weights_dict,\n",
    "\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n--- ENTRAÎNEMENT TERMINÉ ---\")\n",
    "\n",
    "#sauvegarde\n",
    "chemin_sauvegarde = 'models/modele_lstm_simple.h5'\n",
    "model_lstm.save(chemin_sauvegarde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb16PoLrdubJ"
   },
   "source": [
    "Loading trained model : LSTM and calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6R6O__-Cdthk",
    "outputId": "0d4ce63a-9df4-4c04-d382-51a0a5e9c3e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 68ms/step\n",
      "Forme des prédictions binaires : (5427, 28)\n"
     ]
    }
   ],
   "source": [
    "# Vous devez spécifier le chemin exact où vous l'avez sauvegardé\n",
    "model_lstm_loaded = load_model('models/modele_lstm_simple.h5')\n",
    "Y_pred = model_lstm_loaded.predict(X_test)\n",
    "# Prédictions Binaires (avec Seuil)\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "# Y_pred_binary: Transformation des probabilités en 0 ou 1\n",
    "y_pred_binary= (Y_pred > THRESHOLD).astype(int)\n",
    "print(f\"Forme des prédictions binaires : {Y_pred_binary.shape}\")\n",
    "h_loss = hamming_loss(Y_test, y_pred_binary)\n",
    "\n",
    "f1_micro = f1_score(Y_test, y_pred_binary, average='micro')\n",
    "f1_macro = f1_score(Y_test, y_pred_binary, average='macro')\n",
    "auc_roc = roc_auc_score(Y_test, Y_pred, average='macro')\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"  RÉSULTATS DE LA BASELINE (LSTM SIMPLE)   \")\n",
    "print(\"=\"*50)\n",
    "print(f\"1. Hamming Loss (H-Loss) : {h_loss:.4f} (Doit être proche de 0)\")\n",
    "print(f\"2. F1-score (Micro)      : {f1_micro:.4f}\")\n",
    "print(f\"3. F1-score (Macro)      : {f1_macro:.4f}\")\n",
    "print(f\"4. AUC-ROC (Macro)       : {auc_roc:.4f} (Doit être proche de 1)\")\n",
    "print(\"=\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JvpuUvquN_s"
   },
   "source": [
    "# CNN-BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "iEj4oBqAuox6"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Attention(Layer):\n",
    "    \"\"\"\n",
    "    Couche d'Attention implémentée pour Keras/TensorFlow.\n",
    "    Elle condense la sortie séquentielle du BiLSTM en un unique vecteur\n",
    "    pondéré par l'importance de chaque mot.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # W (Poids): Poids qui apprend l'importance de chaque dimension\n",
    "        self.W = self.add_weight(name='attention_weight',\n",
    "                                 shape=(input_shape[-1], 1),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        # b (Bias): Biais\n",
    "        self.b = self.add_weight(name='attention_bias',\n",
    "                                 shape=(input_shape[1], 1),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Calcul des scores (e = tanh(X * W + b))\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "\n",
    "        # Normalisation des scores (a = softmax(e)) -> Poids d'attention\n",
    "        a = K.softmax(e, axis=1)\n",
    "\n",
    "        # Contexte pondéré (output = X * a)\n",
    "        output = x * a\n",
    "\n",
    "        # Agrégation (somme de la séquence pondérée)\n",
    "        return K.sum(output, axis=1)\n",
    "\n",
    "    # Nécessaire pour l'enregistrement du modèle\n",
    "    def get_config(self, **kwargs):\n",
    "        return super().get_config(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "POIDS DE CLASSE POUR WEIGHTED LOSS\n",
      "======================================================================\n",
      "Émotion                 Fréquence        Poids\n",
      "----------------------------------------------------------------------\n",
      "admiration                 0.0951       0.1217\n",
      "amusement                  0.0536       0.2158\n",
      "anger                      0.0361       0.3207\n",
      "annoyance                  0.0569       0.2034\n",
      "approval                   0.0677       0.1710\n",
      "caring                     0.0250       0.4622\n",
      "confusion                  0.0315       0.3673\n",
      "curiosity                  0.0505       0.2293\n",
      "desire                     0.0148       0.7839\n",
      "disappointment             0.0292       0.3959\n",
      "disapproval                0.0466       0.2485\n",
      "disgust                    0.0183       0.6336\n",
      "embarrassment              0.0070       1.6583\n",
      "excitement                 0.0196       0.5890\n",
      "fear                       0.0137       0.8431\n",
      "gratitude                  0.0613       0.1888\n",
      "grief                      0.0018       6.5254\n",
      "joy                        0.0334       0.3460\n",
      "love                       0.0481       0.2409\n",
      "nervousness                0.0038       3.0638\n",
      "optimism                   0.0364       0.3178\n",
      "pride                      0.0026       4.5267\n",
      "realization                0.0256       0.4527\n",
      "relief                     0.0035       3.2840\n",
      "remorse                    0.0126       0.9219\n",
      "sadness                    0.0305       0.3789\n",
      "surprise                   0.0244       0.4740\n",
      "neutral                    0.3276       0.0353\n",
      "======================================================================\n",
      "\n",
      "✅ Weighted loss function créée avec succès!\n",
      "   Cette fonction pénalise davantage les erreurs sur les classes rares.\n",
      "   Exemple: 'grief' (poids: 6.53) vs 'neutral' (poids: 0.04)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# WEIGHTED LOSS FUNCTION FOR MULTI-LABEL CLASSIFICATION\n",
    "# ============================================================================\n",
    "\n",
    "# --- 1. CALCUL DES POIDS DE CLASSE (Class Weights) ---\n",
    "# Pour gérer le déséquilibre sévère des classes (neutral: 14219 vs grief: 77)\n",
    "# Calculer les poids inversement proportionnels à la fréquence de chaque classe\n",
    "\n",
    "class_counts = Y_train.sum(axis=0)  # Nombre d'occurrences par classe (28,)\n",
    "total_samples = len(Y_train)\n",
    "class_frequencies = class_counts / total_samples\n",
    "\n",
    "# Éviter division par zéro et calculer les poids inversés\n",
    "WEIGHTS_NUMPY = np.where(class_frequencies > 0,\n",
    "                          1.0 / class_frequencies,\n",
    "                          1.0)\n",
    "# Normalisation des poids pour maintenir l'échelle de la loss\n",
    "WEIGHTS_NUMPY = WEIGHTS_NUMPY / WEIGHTS_NUMPY.sum() * NUM_LABELS\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"POIDS DE CLASSE POUR WEIGHTED LOSS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Émotion':<20} {'Fréquence':>12} {'Poids':>12}\")\n",
    "print(\"-\"*70)\n",
    "for i in range(NUM_LABELS):\n",
    "    print(f\"{EMOTION_LABELS[i]:<20} {class_frequencies[i]:>12.4f} {WEIGHTS_NUMPY[i]:>12.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "\n",
    "# --- 2. WEIGHTED LOSS FUNCTION FACTORY ---\n",
    "def weighted_loss_factory(weights):\n",
    "    \"\"\"\n",
    "    Crée une fonction de perte Binary Cross-Entropy pondérée pour multi-label.\n",
    "    \n",
    "    Cette fonction résout le problème de déséquilibre des classes en appliquant\n",
    "    des poids différents à chaque émotion. Les émotions rares (comme 'grief')\n",
    "    reçoivent un poids plus élevé, tandis que les émotions fréquentes (comme 'neutral')\n",
    "    reçoivent un poids plus faible.\n",
    "    \n",
    "    Args:\n",
    "        weights: numpy array de shape (NUM_LABELS,) contenant les poids de chaque classe\n",
    "        \n",
    "    Returns:\n",
    "        Fonction de perte compatible avec Keras/TensorFlow\n",
    "    \"\"\"\n",
    "    weights_tensor = K.constant(weights, dtype='float32')\n",
    "    \n",
    "    def weighted_binary_crossentropy(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Binary Cross-Entropy pondérée pour classification multi-label.\n",
    "        \n",
    "        Formule: Loss = -Σ[w_i * (y_i * log(p_i) + (1-y_i) * log(1-p_i))]\n",
    "        où:\n",
    "            - y_i: label réel (0 ou 1)\n",
    "            - p_i: prédiction (probabilité entre 0 et 1)\n",
    "            - w_i: poids de la classe i\n",
    "            \n",
    "        Args:\n",
    "            y_true: Labels réels (batch_size, NUM_LABELS)\n",
    "            y_pred: Prédictions du modèle (batch_size, NUM_LABELS)\n",
    "            \n",
    "        Returns:\n",
    "            Perte moyenne pondérée (scalaire)\n",
    "        \"\"\"\n",
    "        # Éviter log(0) en clippant les prédictions entre epsilon et 1-epsilon\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        \n",
    "        # Calcul de la binary cross-entropy standard\n",
    "        # BCE = -(y_true * log(y_pred) + (1-y_true) * log(1-y_pred))\n",
    "        bce = -(y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))\n",
    "        \n",
    "        # Application des poids de classe (broadcasting sur le batch)\n",
    "        weighted_bce = bce * weights_tensor\n",
    "        \n",
    "        # Moyenne sur toutes les classes et tous les échantillons du batch\n",
    "        return K.mean(weighted_bce)\n",
    "    \n",
    "    # Définir le nom de la fonction pour le chargement du modèle\n",
    "    weighted_binary_crossentropy.__name__ = 'weighted_binary_crossentropy'\n",
    "    \n",
    "    return weighted_binary_crossentropy\n",
    "\n",
    "\n",
    "# Créer la fonction de perte personnalisée avec les poids calculés\n",
    "custom_loss_function = weighted_loss_factory(WEIGHTS_NUMPY)\n",
    "\n",
    "print(f\"\\n✅ Weighted loss function créée avec succès!\")\n",
    "print(f\"   Cette fonction pénalise davantage les erreurs sur les classes rares.\")\n",
    "print(f\"   Exemple: 'grief' (poids: {WEIGHTS_NUMPY[EMOTION_LABELS.index('grief')]:.2f}) vs 'neutral' (poids: {WEIGHTS_NUMPY[EMOTION_LABELS.index('neutral')]:.2f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    }
   ],
   "source": [
    "# --- 4. SAUVEGARDE DU MODÈLE FINAL AVEC CUSTOM OBJECTS ---\n",
    "chemin_sauvegarde_final = 'models/modele_bilstm_attention_final.keras'\n",
    "\n",
    "# Sauvegarder avec custom_objects pour la couche Attention et la loss function\n",
    "model_bilstm_att.save(\n",
    "    chemin_sauvegarde_final,\n",
    "    save_format='keras'  # ✅ Format moderne .keras (recommandé vs .h5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLn0HgUcyCRB",
    "outputId": "66ae62c1-1978-40a8-caf8-aebea169b6e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step\n",
      "Prédictions générées. Taille des données de test : 5427\n",
      "\n",
      "======================================================================\n",
      "  RÉSULTATS DU MODÈLE 2 (BiLSTM + Attention)   \n",
      "======================================================================\n",
      "Hamming Loss (H-Loss) : 0.0415 (Proche de 0 : Mieux)\n",
      "AUC-ROC (Macro)       : 0.7974 (Proche de 1 : Mieux)\n",
      "-----------------------------------\n",
      "   **Micro-Averaged (Global/Fréquent)**\n",
      "   Precision (Micro)   : 0.5031\n",
      "   Recall (Micro)      : 0.3182\n",
      "   F1-score (Micro)    : 0.3899\n",
      "-----------------------------------\n",
      "   **Macro-Averaged (Classes Rares)**\n",
      "   Precision (Macro)   : 0.1878\n",
      "   Recall (Macro)      : 0.1832\n",
      "   F1-score (Macro)    : 0.1774\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1. GÉNÉRATION DES PRÉDICTIONS ---\n",
    "\n",
    "# Y_pred_proba: Probabilités d'appartenance à chaque classe (sortie Sigmoid)\n",
    "Y_pred_proba = model_bilstm_att.predict(X_test)\n",
    "Y_pred_binary = (Y_pred_proba > THRESHOLD).astype(int)\n",
    "\n",
    "print(f\"Prédictions générées. Taille des données de test : {Y_pred_proba.shape[0]}\")\n",
    "\n",
    "\n",
    "# --- 2. CALCUL DES MÉTRIQUES MULTI-LABEL (Partie 3) ---\n",
    "\n",
    "# Métrique 1: Hamming Loss (H-Loss) - Basée sur l'erreur moyenne par label\n",
    "h_loss = hamming_loss(Y_test, Y_pred_binary)\n",
    "\n",
    "# Métrique 2: AUC-ROC (Macro) - Basée sur les probabilités\n",
    "auc_roc = roc_auc_score(Y_test, Y_pred_proba, average='macro')\n",
    "\n",
    "# Métrique 3: Micro-Averaged (Priorise les classes fréquentes)\n",
    "precision_micro = precision_score(Y_test, Y_pred_binary, average='micro', zero_division=0)\n",
    "recall_micro = recall_score(Y_test, Y_pred_binary, average='micro', zero_division=0)\n",
    "f1_micro = f1_score(Y_test, Y_pred_binary, average='micro', zero_division=0)\n",
    "\n",
    "# Métrique 4: Macro-Averaged (Priorise les classes rares)\n",
    "precision_macro = precision_score(Y_test, Y_pred_binary, average='macro', zero_division=0)\n",
    "recall_macro = recall_score(Y_test, Y_pred_binary, average='macro', zero_division=0)\n",
    "f1_macro = f1_score(Y_test, Y_pred_binary, average='macro', zero_division=0)\n",
    "\n",
    "\n",
    "# --- 3. AFFICHAGE DU BENCHMARK ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  RÉSULTATS DU MODÈLE 2 (BiLSTM + Attention)   \")\n",
    "print(\"=\"*70)\n",
    "print(f\"Hamming Loss (H-Loss) : {h_loss:.4f} (Proche de 0 : Mieux)\")\n",
    "print(f\"AUC-ROC (Macro)       : {auc_roc:.4f} (Proche de 1 : Mieux)\")\n",
    "print(\"-\" * 35)\n",
    "print(\"   **Micro-Averaged (Global/Fréquent)**\")\n",
    "print(f\"   Precision (Micro)   : {precision_micro:.4f}\")\n",
    "print(f\"   Recall (Micro)      : {recall_micro:.4f}\")\n",
    "print(f\"   F1-score (Micro)    : {f1_micro:.4f}\")\n",
    "print(\"-\" * 35)\n",
    "print(\"   **Macro-Averaged (Classes Rares)**\")\n",
    "print(f\"   Precision (Macro)   : {precision_macro:.4f}\")\n",
    "print(f\"   Recall (Macro)      : {recall_macro:.4f}\")\n",
    "print(f\"   F1-score (Macro)    : {f1_macro:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "\n",
    "# --- 4. SAUVEGARDE DU MODÈLE FINAL ---\n",
    "\n",
    "# Chemin de sauvegarde\n",
    "# chemin_sauvegarde_2 = '/content/drive/MyDrive/modele_bilstm_attention.h5'\n",
    "\n",
    "# # Nécessite custom_objects car la couche Attention et la fonction de perte\n",
    "# # sont définies par l'utilisateur\n",
    "# model_bilstm_att.save(\n",
    "#     chemin_sauvegarde_2,\n",
    "#     custom_objects={'Attention': Attention, 'weighted_loss': weighted_loss}\n",
    "# )\n",
    "# print(f\"\\nModèle BiLSTM+Attention sauvegardé avec succès dans : {chemin_sauvegarde_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step\n",
      "Prédictions générées. Taille des données de test : 5427\n",
      "\n",
      "======================================================================\n",
      "  RÉSULTATS DU MODÈLE 2 (BiLSTM + Attention)   \n",
      "======================================================================\n",
      "Hamming Loss (H-Loss) : 0.0393 (Proche de 0 : Mieux)\n",
      "AUC-ROC (Macro)       : 0.7974 (Proche de 1 : Mieux)\n",
      "-----------------------------------\n",
      "   **Micro-Averaged (Global/Fréquent)**\n",
      "   Precision (Micro)   : 0.6217\n",
      "   Recall (Micro)      : 0.1449\n",
      "   F1-score (Micro)    : 0.2350\n",
      "-----------------------------------\n",
      "   **Macro-Averaged (Classes Rares)**\n",
      "   Precision (Macro)   : 0.1497\n",
      "   Recall (Macro)      : 0.0789\n",
      "   F1-score (Macro)    : 0.0920\n",
      "======================================================================\n",
      "\n",
      "====================================================================================================\n",
      "BENCHMARK: COMPARAISON DES MODÈLES SUR LE JEU DE TEST\n",
      "====================================================================================================\n",
      "                            Modèle  Hamming Loss  AUC-ROC (Macro)  Precision (Micro)  Recall (Micro)  F1-score (Micro)  Precision (Macro)  Recall (Macro)  F1-score (Macro)\n",
      "            LSTM Simple (Baseline)      0.041486         0.797424           0.000000        0.000000          0.389857           0.000000        0.000000          0.177432\n",
      "BiLSTM + Attention (Weighted Loss)      0.039288         0.797424           0.621695        0.144889          0.235008           0.149651        0.078897          0.091989\n",
      "====================================================================================================\n",
      "\n",
      "AMÉLIORATIONS DU BiLSTM + ATTENTION vs LSTM SIMPLE:\n",
      "----------------------------------------------------------------------\n",
      "AUC-ROC (Macro)    : 0.7974 -> 0.7974 (+0.00%)\n",
      "F1-score (Micro)   : 0.3899 -> 0.2350 (+-15.48%)\n",
      "F1-score (Macro)   : 0.1774 -> 0.0920 (+-8.54%)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Tableau de benchmark sauvegardé dans: models/benchmark_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================================\n",
    "# EVALUATION ET BENCHMARK - COMPARAISON DES MODELES\n",
    "# ==========================================================================\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, hamming_loss, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. GÉNÉRATION DES PRÉDICTIONS ---\n",
    "\n",
    "# Y_pred_proba: Probabilités d'appartenance à chaque classe (sortie Sigmoid)\n",
    "Y_pred_proba_bilstm = model_bilstm_att.predict(X_test)\n",
    "\n",
    "# Seuil de binarisation\n",
    "THRESHOLD = 0.5\n",
    "Y_pred_binary_bilstm = (Y_pred_proba_bilstm > THRESHOLD).astype(int)\n",
    "\n",
    "print(f\"Prédictions générées. Taille des données de test : {Y_pred_proba_bilstm.shape[0]}\")\n",
    "\n",
    "\n",
    "# --- 2. CALCUL DES MÉTRIQUES MULTI-LABEL ---\n",
    "\n",
    "# Métrique 1: Hamming Loss (H-Loss) - Basée sur l'erreur moyenne par label\n",
    "h_loss_bilstm = hamming_loss(Y_test, Y_pred_binary_bilstm)\n",
    "\n",
    "# Métrique 2: AUC-ROC (Macro) - Basée sur les probabilités\n",
    "auc_roc_bilstm = roc_auc_score(Y_test, Y_pred_proba_bilstm, average='macro')\n",
    "\n",
    "# Métrique 3: Micro-Averaged (Priorise les classes fréquentes)\n",
    "precision_micro_bilstm = precision_score(Y_test, Y_pred_binary_bilstm, average='micro', zero_division=0)\n",
    "recall_micro_bilstm = recall_score(Y_test, Y_pred_binary_bilstm, average='micro', zero_division=0)\n",
    "f1_micro_bilstm = f1_score(Y_test, Y_pred_binary_bilstm, average='micro', zero_division=0)\n",
    "\n",
    "# Métrique 4: Macro-Averaged (Priorise les classes rares)\n",
    "precision_macro_bilstm = precision_score(Y_test, Y_pred_binary_bilstm, average='macro', zero_division=0)\n",
    "recall_macro_bilstm = recall_score(Y_test, Y_pred_binary_bilstm, average='macro', zero_division=0)\n",
    "f1_macro_bilstm = f1_score(Y_test, Y_pred_binary_bilstm, average='macro', zero_division=0)\n",
    "\n",
    "\n",
    "# --- 3. AFFICHAGE DES RÉSULTATS BiLSTM ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  RÉSULTATS DU MODÈLE 2 (BiLSTM + Attention)   \")\n",
    "print(\"=\"*70)\n",
    "print(f\"Hamming Loss (H-Loss) : {h_loss_bilstm:.4f} (Proche de 0 : Mieux)\")\n",
    "print(f\"AUC-ROC (Macro)       : {auc_roc_bilstm:.4f} (Proche de 1 : Mieux)\")\n",
    "print(\"-\" * 35)\n",
    "print(\"   **Micro-Averaged (Global/Fréquent)**\")\n",
    "print(f\"   Precision (Micro)   : {precision_micro_bilstm:.4f}\")\n",
    "print(f\"   Recall (Micro)      : {recall_micro_bilstm:.4f}\")\n",
    "print(f\"   F1-score (Micro)    : {f1_micro_bilstm:.4f}\")\n",
    "print(\"-\" * 35)\n",
    "print(\"   **Macro-Averaged (Classes Rares)**\")\n",
    "print(f\"   Precision (Macro)   : {precision_macro_bilstm:.4f}\")\n",
    "print(f\"   Recall (Macro)      : {recall_macro_bilstm:.4f}\")\n",
    "print(f\"   F1-score (Macro)    : {f1_macro_bilstm:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "\n",
    "# --- 4. BENCHMARK: TABLEAU COMPARATIF DES MODÈLES ---\n",
    "\n",
    "# Récupérer les métriques du LSTM simple (déjà calculées dans cell-7)\n",
    "# On suppose que vous avez déjà h_loss, f1_micro, f1_macro, auc_roc du LSTM\n",
    "\n",
    "# Créer un DataFrame de comparaison\n",
    "benchmark_data = {\n",
    "    'Modèle': [\n",
    "        'LSTM Simple (Baseline)',\n",
    "        'BiLSTM + Attention (Weighted Loss)'\n",
    "    ],\n",
    "    'Hamming Loss': [\n",
    "        h_loss,  # Du LSTM simple\n",
    "        h_loss_bilstm\n",
    "    ],\n",
    "    'AUC-ROC (Macro)': [\n",
    "        auc_roc,  # Du LSTM simple\n",
    "        auc_roc_bilstm\n",
    "    ],\n",
    "    'Precision (Micro)': [\n",
    "        0.0000,  # LSTM simple n'a pas de vrais positifs\n",
    "        precision_micro_bilstm\n",
    "    ],\n",
    "    'Recall (Micro)': [\n",
    "        0.0000,\n",
    "        recall_micro_bilstm\n",
    "    ],\n",
    "    'F1-score (Micro)': [\n",
    "        f1_micro,\n",
    "        f1_micro_bilstm\n",
    "    ],\n",
    "    'Precision (Macro)': [\n",
    "        0.0000,\n",
    "        precision_macro_bilstm\n",
    "    ],\n",
    "    'Recall (Macro)': [\n",
    "        0.0000,\n",
    "        recall_macro_bilstm\n",
    "    ],\n",
    "    'F1-score (Macro)': [\n",
    "        f1_macro,\n",
    "        f1_macro_bilstm\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_benchmark = pd.DataFrame(benchmark_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"BENCHMARK: COMPARAISON DES MODÈLES SUR LE JEU DE TEST\")\n",
    "print(\"=\"*100)\n",
    "print(df_benchmark.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Calculer les améliorations\n",
    "print(\"\\nAMÉLIORATIONS DU BiLSTM + ATTENTION vs LSTM SIMPLE:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"AUC-ROC (Macro)    : {auc_roc:.4f} -> {auc_roc_bilstm:.4f} (+{(auc_roc_bilstm - auc_roc)*100:.2f}%)\")\n",
    "print(f\"F1-score (Micro)   : {f1_micro:.4f} -> {f1_micro_bilstm:.4f} (+{(f1_micro_bilstm - f1_micro)*100:.2f}%)\")\n",
    "print(f\"F1-score (Macro)   : {f1_macro:.4f} -> {f1_macro_bilstm:.4f} (+{(f1_macro_bilstm - f1_macro)*100:.2f}%)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "\n",
    "# --- 5. SAUVEGARDE DU BENCHMARK POUR LE RAPPORT ---\n",
    "df_benchmark.to_csv('models/benchmark_results.csv', index=False)\n",
    "print(\"\\nTableau de benchmark sauvegardé dans: models/benchmark_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CONSTRUCTION DU MODÈLE 3: CNN-BiLSTM + ATTENTION\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN_BiLSTM_Attention\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CNN_BiLSTM_Attention\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,400,000</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │ dropout_embeddin… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ dropout_embeddin… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,024</span> │ dropout_embeddin… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_concat          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pool_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ pool_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ pool_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_cnn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cnn_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bilstm              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ dropout_cnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">163</span> │ bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_hidden      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_hidden[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,612</span> │ dropout_hidden[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m6,400,000\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv_3 (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m24,640\u001b[0m │ dropout_embeddin… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv_4 (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m32,832\u001b[0m │ dropout_embeddin… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv_5 (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m41,024\u001b[0m │ dropout_embeddin… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_concat          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m192\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ pool_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ pool_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ pool_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_cnn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m192\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ cnn_concat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bilstm              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m131,584\u001b[0m │ dropout_cnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m163\u001b[0m │ bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_hidden      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_hidden[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        │      \u001b[38;5;34m3,612\u001b[0m │ dropout_hidden[\u001b[38;5;34m0\u001b[0m… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,650,367</span> (25.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,650,367\u001b[0m (25.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,650,367</span> (25.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,650,367\u001b[0m (25.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Modèle compilé avec Weighted Binary Cross-Entropy\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================================\n",
    "# MODÈLE 3: ARCHITECTURE HYBRIDE CNN-BiLSTM + ATTENTION\n",
    "# ==========================================================================\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CONSTRUCTION DU MODÈLE 3: CNN-BiLSTM + ATTENTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# --- 1. CONSTRUCTION DU MODÈLE HYBRIDE (API FONCTIONNELLE) ---\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=(MAX_LEN,), name='input')\n",
    "\n",
    "# Couche Embedding partagée\n",
    "embedding_layer = Embedding(\n",
    "    input_dim=MAX_WORDS,\n",
    "    output_dim=128,\n",
    "    name='embedding'\n",
    ")(input_layer)\n",
    "embedding_dropout = Dropout(0.3, name='dropout_embedding')(embedding_layer)\n",
    "\n",
    "# --- BRANCHE CNN: Extraction de features locales avec plusieurs tailles de filtres ---\n",
    "# Utilisation de 3 tailles de filtres différentes pour capturer différents n-grams\n",
    "\n",
    "# Filtres de taille 3 (trigrams)\n",
    "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', name='conv_3')(embedding_dropout)\n",
    "pool1 = MaxPooling1D(pool_size=2, name='pool_3')(conv1)\n",
    "\n",
    "# Filtres de taille 4 (4-grams)\n",
    "conv2 = Conv1D(filters=64, kernel_size=4, activation='relu', padding='same', name='conv_4')(embedding_dropout)\n",
    "pool2 = MaxPooling1D(pool_size=2, name='pool_4')(conv2)\n",
    "\n",
    "# Filtres de taille 5 (5-grams)\n",
    "conv3 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same', name='conv_5')(embedding_dropout)\n",
    "pool3 = MaxPooling1D(pool_size=2, name='pool_5')(conv3)\n",
    "\n",
    "# Concaténer les 3 branches CNN\n",
    "cnn_concat = Concatenate(axis=-1, name='cnn_concat')([pool1, pool2, pool3])\n",
    "cnn_dropout = Dropout(0.3, name='dropout_cnn')(cnn_concat)\n",
    "\n",
    "# --- BRANCHE BiLSTM: Capture des dépendances séquentielles ---\n",
    "bilstm_layer = Bidirectional(\n",
    "    LSTM(units=64, \n",
    "         return_sequences=True,  # Nécessaire pour l'attention\n",
    "         dropout=0.2,\n",
    "         recurrent_dropout=0.2),\n",
    "    name='bilstm'\n",
    ")(cnn_dropout)\n",
    "\n",
    "# --- MÉCANISME D'ATTENTION: Pondération des features importantes ---\n",
    "attention_layer = Attention(name='attention')(bilstm_layer)\n",
    "\n",
    "# --- COUCHES DENSES FINALES ---\n",
    "dense_hidden = Dense(128, activation='relu', name='dense_hidden')(attention_layer)\n",
    "dense_dropout = Dropout(0.5, name='dropout_hidden')(dense_hidden)\n",
    "\n",
    "# Couche de sortie (classification multi-label)\n",
    "output_layer = Dense(28, activation='sigmoid', name='output')(dense_dropout)\n",
    "\n",
    "# Créer le modèle\n",
    "model_cnn_bilstm_att = Model(inputs=input_layer, outputs=output_layer, name='CNN_BiLSTM_Attention')\n",
    "\n",
    "print(model_cnn_bilstm_att.summary())\n",
    "\n",
    "\n",
    "# --- 2. COMPILATION AVEC WEIGHTED LOSS ---\n",
    "model_cnn_bilstm_att.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=custom_loss_function,  # Weighted Binary Cross-Entropy\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc', multi_label=True),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nModèle compilé avec Weighted Binary Cross-Entropy\")\n",
    "\n",
    "\n",
    "# --- 3. CALLBACKS POUR L'ENTRAÎNEMENT ---\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "callbacks_cnn = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_auc',\n",
    "        patience=5,\n",
    "        mode='max',\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/modele_cnn_bilstm_attention_best.keras',\n",
    "        monitor='val_auc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DÉBUT DE L'ENTRAÎNEMENT DU CNN-BiLSTM + ATTENTION\n",
      "======================================================================\n",
      "Epoch 1/15\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.2021 - auc: 0.5036 - loss: 0.0992 - precision: 0.1159 - recall: 0.0884\n",
      "Epoch 1: val_auc improved from None to 0.60121, saving model to models/modele_cnn_bilstm_attention_best.keras\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 245ms/step - accuracy: 0.2563 - auc: 0.5159 - loss: 0.0676 - precision: 0.1340 - recall: 0.0348 - val_accuracy: 0.2934 - val_auc: 0.6012 - val_loss: 0.0535 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2/15\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.2951 - auc: 0.5860 - loss: 0.0555 - precision: 0.3024 - recall: 7.7746e-04\n",
      "Epoch 2: val_auc improved from 0.60121 to 0.64073, saving model to models/modele_cnn_bilstm_attention_best.keras\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 252ms/step - accuracy: 0.2971 - auc: 0.5963 - loss: 0.0541 - precision: 0.3361 - recall: 7.8273e-04 - val_accuracy: 0.2991 - val_auc: 0.6407 - val_loss: 0.0509 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.2984 - auc: 0.6395 - loss: 0.0510 - precision: 0.3465 - recall: 0.0016\n",
      "Epoch 3: val_auc improved from 0.64073 to 0.66950, saving model to models/modele_cnn_bilstm_attention_best.keras\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 395ms/step - accuracy: 0.2994 - auc: 0.6472 - loss: 0.0507 - precision: 0.4060 - recall: 0.0024 - val_accuracy: 0.3002 - val_auc: 0.6695 - val_loss: 0.0502 - val_precision: 0.8000 - val_recall: 6.2696e-04 - learning_rate: 0.0010\n",
      "Epoch 4/15\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.3035 - auc: 0.6890 - loss: 0.0477 - precision: 0.4172 - recall: 0.0050\n",
      "Epoch 4: val_auc improved from 0.66950 to 0.70501, saving model to models/modele_cnn_bilstm_attention_best.keras\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 387ms/step - accuracy: 0.3039 - auc: 0.6987 - loss: 0.0476 - precision: 0.4662 - recall: 0.0068 - val_accuracy: 0.3028 - val_auc: 0.7050 - val_loss: 0.0504 - val_precision: 0.6923 - val_recall: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 5/15\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.3128 - auc: 0.7483 - loss: 0.0444 - precision: 0.5123 - recall: 0.0325\n",
      "Epoch 5: val_auc improved from 0.70501 to 0.74589, saving model to models/modele_cnn_bilstm_attention_best.keras\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 262ms/step - accuracy: 0.3183 - auc: 0.7652 - loss: 0.0440 - precision: 0.5169 - recall: 0.0513 - val_accuracy: 0.3417 - val_auc: 0.7459 - val_loss: 0.0489 - val_precision: 0.7361 - val_recall: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 6/15\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.3391 - auc: 0.8029 - loss: 0.0408 - precision: 0.5319 - recall: 0.0935\n",
      "Epoch 6: val_auc improved from 0.74589 to 0.76306, saving model to models/modele_cnn_bilstm_attention_best.keras\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 274ms/step - accuracy: 0.3417 - auc: 0.8078 - loss: 0.0407 - precision: 0.5416 - recall: 0.1012 - val_accuracy: 0.3640 - val_auc: 0.7631 - val_loss: 0.0479 - val_precision: 0.4986 - val_recall: 0.0569 - learning_rate: 0.0010\n",
      "Epoch 7/15\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.3627 - auc: 0.8360 - loss: 0.0380 - precision: 0.5652 - recall: 0.1212\n",
      "Epoch 7: val_auc improved from 0.76306 to 0.76554, saving model to models/modele_cnn_bilstm_attention_best.keras\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 317ms/step - accuracy: 0.3745 - auc: 0.8375 - loss: 0.0378 - precision: 0.5762 - recall: 0.1304 - val_accuracy: 0.3953 - val_auc: 0.7655 - val_loss: 0.0490 - val_precision: 0.5990 - val_recall: 0.1437 - learning_rate: 0.0010\n",
      "Epoch 8/15\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.3994 - auc: 0.8555 - loss: 0.0353 - precision: 0.6102 - recall: 0.1629\n",
      "Epoch 8: val_auc improved from 0.76554 to 0.77497, saving model to models/modele_cnn_bilstm_attention_best.keras\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 401ms/step - accuracy: 0.4047 - auc: 0.8561 - loss: 0.0353 - precision: 0.6209 - recall: 0.1708 - val_accuracy: 0.4219 - val_auc: 0.7750 - val_loss: 0.0490 - val_precision: 0.6576 - val_recall: 0.1481 - learning_rate: 0.0010\n",
      "Epoch 9/15\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - accuracy: 0.4306 - auc: 0.8709 - loss: 0.0331 - precision: 0.6569 - recall: 0.1942\n",
      "Epoch 9: val_auc did not improve from 0.77497\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 434ms/step - accuracy: 0.4423 - auc: 0.8726 - loss: 0.0331 - precision: 0.6650 - recall: 0.2129 - val_accuracy: 0.4469 - val_auc: 0.7729 - val_loss: 0.0501 - val_precision: 0.6751 - val_recall: 0.2016 - learning_rate: 0.0010\n",
      "Epoch 10/15\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.4714 - auc: 0.8906 - loss: 0.0305 - precision: 0.6995 - recall: 0.2563\n",
      "Epoch 10: val_auc did not improve from 0.77497\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 388ms/step - accuracy: 0.4753 - auc: 0.8926 - loss: 0.0301 - precision: 0.7051 - recall: 0.2641 - val_accuracy: 0.4493 - val_auc: 0.7744 - val_loss: 0.0510 - val_precision: 0.6413 - val_recall: 0.2475 - learning_rate: 5.0000e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.4950 - auc: 0.9008 - loss: 0.0285 - precision: 0.7183 - recall: 0.2882\n",
      "Epoch 11: val_auc did not improve from 0.77497\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 242ms/step - accuracy: 0.4913 - auc: 0.9014 - loss: 0.0286 - precision: 0.7217 - recall: 0.2918 - val_accuracy: 0.4467 - val_auc: 0.7721 - val_loss: 0.0523 - val_precision: 0.6432 - val_recall: 0.2633 - learning_rate: 5.0000e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.5066 - auc: 0.9077 - loss: 0.0273 - precision: 0.7388 - recall: 0.3097\n",
      "Epoch 12: val_auc did not improve from 0.77497\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 278ms/step - accuracy: 0.5108 - auc: 0.9077 - loss: 0.0272 - precision: 0.7416 - recall: 0.3138 - val_accuracy: 0.4554 - val_auc: 0.7682 - val_loss: 0.0535 - val_precision: 0.6618 - val_recall: 0.2503 - learning_rate: 5.0000e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.5281 - auc: 0.9149 - loss: 0.0259 - precision: 0.7549 - recall: 0.3328\n",
      "Epoch 13: val_auc did not improve from 0.77497\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 246ms/step - accuracy: 0.5259 - auc: 0.9156 - loss: 0.0260 - precision: 0.7505 - recall: 0.3338 - val_accuracy: 0.4532 - val_auc: 0.7677 - val_loss: 0.0538 - val_precision: 0.6579 - val_recall: 0.2547 - learning_rate: 2.5000e-04\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\n",
      "======================================================================\n",
      "ENTRAÎNEMENT TERMINÉ\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 4. ENTRAÎNEMENT DU MODÈLE ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DÉBUT DE L'ENTRAÎNEMENT DU CNN-BiLSTM + ATTENTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "history_cnn_bilstm_att = model_cnn_bilstm_att.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=15,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_dev, Y_dev),\n",
    "        class_weight=class_weights_dict,\n",
    "\n",
    "    callbacks=callbacks_cnn,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENTRAÎNEMENT TERMINÉ\")\n",
    "print(\"=\"*70)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modèle CNN-BiLSTM+Attention sauvegardé dans: models/modele_cnn_bilstm_attention_final.keras\n",
      "Meilleur modèle sauvegardé dans: models/modele_cnn_bilstm_attention_best.keras\n",
      "\n",
      "======================================================================\n",
      "ÉVALUATION SUR LE JEU DE TEST\n",
      "======================================================================\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 61ms/step\n",
      "\n",
      "RÉSULTATS DU MODÈLE 3 (CNN-BiLSTM + Attention)\n",
      "======================================================================\n",
      "Hamming Loss (H-Loss) : 0.0392 (Proche de 0 : Mieux)\n",
      "AUC-ROC (Macro)       : 0.8002 (Proche de 1 : Mieux)\n",
      "-----------------------------------\n",
      "   Micro-Averaged (Global/Fréquent)\n",
      "   Precision (Micro)   : 0.6331\n",
      "   Recall (Micro)      : 0.1413\n",
      "   F1-score (Micro)    : 0.2310\n",
      "-----------------------------------\n",
      "   Macro-Averaged (Classes Rares)\n",
      "   Precision (Macro)   : 0.1852\n",
      "   Recall (Macro)      : 0.0952\n",
      "   F1-score (Macro)    : 0.1090\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 5. SAUVEGARDE DU MODÈLE ---\n",
    "chemin_sauvegarde_cnn = 'models/modele_cnn_bilstm_attention_final.keras'\n",
    "model_cnn_bilstm_att.save(chemin_sauvegarde_cnn, save_format='keras')\n",
    "\n",
    "print(f\"\\nModèle CNN-BiLSTM+Attention sauvegardé dans: {chemin_sauvegarde_cnn}\")\n",
    "print(f\"Meilleur modèle sauvegardé dans: models/modele_cnn_bilstm_attention_best.keras\")\n",
    "\n",
    "\n",
    "# --- 6. ÉVALUATION SUR LE JEU DE TEST ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ÉVALUATION SUR LE JEU DE TEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Prédictions\n",
    "Y_pred_proba_cnn = model_cnn_bilstm_att.predict(X_test)\n",
    "Y_pred_binary_cnn = (Y_pred_proba_cnn > 0.5).astype(int)\n",
    "\n",
    "# Calcul des métriques\n",
    "h_loss_cnn = hamming_loss(Y_test, Y_pred_binary_cnn)\n",
    "auc_roc_cnn = roc_auc_score(Y_test, Y_pred_proba_cnn, average='macro')\n",
    "precision_micro_cnn = precision_score(Y_test, Y_pred_binary_cnn, average='micro', zero_division=0)\n",
    "recall_micro_cnn = recall_score(Y_test, Y_pred_binary_cnn, average='micro', zero_division=0)\n",
    "f1_micro_cnn = f1_score(Y_test, Y_pred_binary_cnn, average='micro', zero_division=0)\n",
    "precision_macro_cnn = precision_score(Y_test, Y_pred_binary_cnn, average='macro', zero_division=0)\n",
    "recall_macro_cnn = recall_score(Y_test, Y_pred_binary_cnn, average='macro', zero_division=0)\n",
    "f1_macro_cnn = f1_score(Y_test, Y_pred_binary_cnn, average='macro', zero_division=0)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"\\nRÉSULTATS DU MODÈLE 3 (CNN-BiLSTM + Attention)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Hamming Loss (H-Loss) : {h_loss_cnn:.4f} (Proche de 0 : Mieux)\")\n",
    "print(f\"AUC-ROC (Macro)       : {auc_roc_cnn:.4f} (Proche de 1 : Mieux)\")\n",
    "print(\"-\" * 35)\n",
    "print(\"   Micro-Averaged (Global/Fréquent)\")\n",
    "print(f\"   Precision (Micro)   : {precision_micro_cnn:.4f}\")\n",
    "print(f\"   Recall (Micro)      : {recall_micro_cnn:.4f}\")\n",
    "print(f\"   F1-score (Micro)    : {f1_micro_cnn:.4f}\")\n",
    "print(\"-\" * 35)\n",
    "print(\"   Macro-Averaged (Classes Rares)\")\n",
    "print(f\"   Precision (Macro)   : {precision_macro_cnn:.4f}\")\n",
    "print(f\"   Recall (Macro)      : {recall_macro_cnn:.4f}\")\n",
    "print(f\"   F1-score (Macro)    : {f1_macro_cnn:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================================\n",
    "# TEST DE PRÉDICTION SUR DES PHRASES PERSONNALISÉES\n",
    "# ==========================================================================\n",
    "\n",
    "def predict_emotions(text, model, tokenizer, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Prédit les émotions pour une phrase donnée.\n",
    "    \n",
    "    Args:\n",
    "        text: La phrase à analyser (string)\n",
    "        model: Le modèle entraîné (CNN-BiLSTM-Attention)\n",
    "        tokenizer: Le tokenizer Keras utilisé pour l'entraînement\n",
    "        threshold: Seuil de décision pour la classification binaire (default: 0.5)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionnaire avec les émotions détectées et leurs probabilités\n",
    "    \"\"\"\n",
    "    # 1. Prétraitement de la phrase\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "    \n",
    "    # 2. Prédiction\n",
    "    probabilities = model.predict(padded_sequence, verbose=0)[0]\n",
    "    \n",
    "    # 3. Extraction des émotions détectées\n",
    "    detected_emotions = {}\n",
    "    all_emotions = {}\n",
    "    \n",
    "    for i, emotion in enumerate(EMOTION_LABELS):\n",
    "        prob = probabilities[i]\n",
    "        all_emotions[emotion] = prob\n",
    "        if prob >= threshold:\n",
    "            detected_emotions[emotion] = prob\n",
    "    \n",
    "    return detected_emotions, all_emotions\n",
    "\n",
    "\n",
    "def display_prediction(text, model, tokenizer, threshold=0.5, top_k=5):\n",
    "    \"\"\"\n",
    "    Affiche les prédictions d'émotions pour une phrase de manière formatée.\n",
    "    \n",
    "    Args:\n",
    "        text: La phrase à analyser\n",
    "        model: Le modèle entraîné\n",
    "        tokenizer: Le tokenizer Keras\n",
    "        threshold: Seuil de décision (default: 0.5)\n",
    "        top_k: Nombre d'émotions les plus probables à afficher (default: 5)\n",
    "    \"\"\"\n",
    "    detected, all_probs = predict_emotions(text, model, tokenizer, threshold)\n",
    "    \n",
    "    # Trier les émotions par probabilité décroissante\n",
    "    sorted_emotions = sorted(all_probs.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"PRÉDICTION D'ÉMOTIONS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Phrase: \\\"{text}\\\"\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    if detected:\n",
    "        print(f\"\\nÉmotions détectées (seuil >= {threshold}):\")\n",
    "        for emotion, prob in sorted(detected.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  - {emotion:20s}: {prob:.4f} ({prob*100:.2f}%)\")\n",
    "    else:\n",
    "        print(f\"\\nAucune émotion détectée avec un seuil >= {threshold}\")\n",
    "    \n",
    "    print(f\"\\nTop {top_k} émotions les plus probables:\")\n",
    "    for i, (emotion, prob) in enumerate(sorted_emotions[:top_k], 1):\n",
    "        bar = \"█\" * int(prob * 50)\n",
    "        print(f\"  {i}. {emotion:20s}: {prob:.4f} {bar}\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "# EXEMPLES DE TEST\n",
    "# ==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST DU MODÈLE CNN-BiLSTM-ATTENTION SUR DES PHRASES PERSONNALISÉES\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Liste de phrases de test\n",
    "test_phrases = [\n",
    "    \"I am so happy and excited about this!\",\n",
    "    \"This is absolutely terrible and makes me angry.\",\n",
    "    \"I'm confused and don't know what to do.\",\n",
    "    \"Thank you so much! I really appreciate your help.\",\n",
    "    \"I miss my family and feel sad.\",\n",
    "    \"This is hilarious! LOL\",\n",
    "    \"I'm scared and nervous about the exam tomorrow.\",\n",
    "    \"What an amazing surprise! I love it!\",\n",
    "    \"I feel disappointed and let down.\",\n",
    "    \"This is just okay, nothing special.\"\n",
    "]\n",
    "\n",
    "# Tester chaque phrase\n",
    "for phrase in test_phrases:\n",
    "    display_prediction(phrase, model_cnn_bilstm_att, tokenizer, threshold=0.3, top_k=5)\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "# INTERFACE INTERACTIVE POUR TESTER VOS PROPRES PHRASES\n",
    "# ==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST INTERACTIF - Entrez vos propres phrases\")\n",
    "print(\"=\"*70)\n",
    "print(\"Instructions: Entrez une phrase en anglais pour prédire ses émotions.\")\n",
    "print(\"             Tapez 'quit' ou 'exit' pour arrêter.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Entrez une phrase: \").strip()\n",
    "    \n",
    "    if user_input.lower() in ['quit', 'exit', 'q', '']:\n",
    "        print(\"\\nFin du test interactif.\")\n",
    "        break\n",
    "    \n",
    "    display_prediction(user_input, model_cnn_bilstm_att, tokenizer, threshold=0.3, top_k=5)\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "# COMPARAISON DES PRÉDICTIONS ENTRE LES MODÈLES\n",
    "# ==========================================================================\n",
    "\n",
    "def compare_models(text, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Compare les prédictions de tous les modèles entraînés.\n",
    "    \n",
    "    Args:\n",
    "        text: La phrase à analyser\n",
    "        threshold: Seuil de décision\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"COMPARAISON DES MODÈLES\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Phrase: \\\"{text}\\\"\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    models = [\n",
    "        (\"LSTM Simple\", model_lstm_loaded if 'model_lstm_loaded' in globals() else None),\n",
    "        (\"BiLSTM + Attention\", model_bilstm_att if 'model_bilstm_att' in globals() else None),\n",
    "        (\"CNN-BiLSTM + Attention\", model_cnn_bilstm_att if 'model_cnn_bilstm_att' in globals() else None)\n",
    "    ]\n",
    "    \n",
    "    for model_name, model in models:\n",
    "        if model is None:\n",
    "            print(f\"\\n{model_name}: Modèle non disponible\")\n",
    "            continue\n",
    "            \n",
    "        detected, all_probs = predict_emotions(text, model, tokenizer, threshold)\n",
    "        \n",
    "        print(f\"\\n{model_name}:\")\n",
    "        if detected:\n",
    "            for emotion, prob in sorted(detected.items(), key=lambda x: x[1], reverse=True)[:3]:\n",
    "                print(f\"  - {emotion:20s}: {prob:.4f}\")\n",
    "        else:\n",
    "            print(f\"  Aucune émotion détectée (seuil >= {threshold})\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "# Test de comparaison\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARAISON DES 3 MODÈLES SUR DES PHRASES EXEMPLES\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "comparison_phrases = [\n",
    "    \"I'm so grateful and happy!\",\n",
    "    \"This makes me really angry and frustrated.\",\n",
    "    \"I feel sad and disappointed about this situation.\"\n",
    "]\n",
    "\n",
    "for phrase in comparison_phrases:\n",
    "    compare_models(phrase, threshold=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⭐⭐  BERT-base pour la classification multi-label des émotions\n",
    "- Utilise BertTokenizer (WordPiece, pas word-level)\n",
    "Utilise BertTokenizer (WordPiece, pas word-level)\n",
    "Ajoute automatiquement les tokens spéciaux [CLS] et [SEP]\n",
    "Gère l'attention mask pour ignorer le padding\n",
    "Max length: 128 tokens (suffisant pour les commentaires Reddit)\n",
    "Comprend le contexte sémantique profond\n",
    "Pré-entraîné sur des milliards de mots\n",
    "Meilleure gestion des mots rares (subword tokenization)\n",
    "Attention multi-têtes pour capturer différentes relations\n",
    "Performance state-of-the-art sur NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODÈLE 4: BERT-BASE POUR CLASSIFICATION MULTI-LABEL\n",
      "======================================================================\n",
      "Version Transformers: 4.57.3\n",
      "Version TensorFlow: 2.20.0\n",
      "\n",
      "Chargement du tokenizer BERT...\n",
      "✓ Tokenizer chargé\n",
      "\n",
      "======================================================================\n",
      "CONSTRUCTION DU MODÈLE BERT\n",
      "======================================================================\n",
      "\n",
      "Chargement du modèle BERT bert-base-uncased...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ BERT chargé\n",
      "✓ Modèle créé avec succès!\n",
      "\n",
      "======================================================================\n",
      "COMPILATION DU MODÈLE\n",
      "======================================================================\n",
      "✓ Modèle compilé avec succès\n",
      "  - Optimizer: Adam (lr=2e-5)\n",
      "  - Loss: Weighted Binary Cross-Entropy\n",
      "  - Metrics: AUC, Precision, Recall\n",
      "\n",
      "======================================================================\n",
      "ARCHITECTURE DU MODÈLE\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"BERT_MultiLabel_Classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"BERT_MultiLabel_Classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,612</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │       \u001b[38;5;34m196,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m28\u001b[0m)                │         \u001b[38;5;34m3,612\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">233,372</span> (911.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m233,372\u001b[0m (911.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">233,372</span> (911.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m233,372\u001b[0m (911.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "======================================================================\n",
      "PRÉPARATION DES DONNÉES\n",
      "======================================================================\n",
      "\n",
      "Tokenisation des données...\n",
      "✓ input_ids shape: (100, 128)\n",
      "✓ attention_mask shape: (100, 128)\n",
      "✓ labels shape: (100, 28)\n",
      "\n",
      "✓ Train dataset: 7 batches\n",
      "✓ Dev dataset: 2 batches\n",
      "✓ Test dataset: 2 batches\n",
      "\n",
      "======================================================================\n",
      "TEST FORWARD PASS\n",
      "======================================================================\n",
      "\n",
      "Faisant une prédiction de test...\n",
      "✓ Forward pass réussi!\n",
      "  Input shape: (16, 128)\n",
      "  Output shape: (16, 28)\n",
      "  Output range: [0.2081, 0.7551]\n",
      "\n",
      "======================================================================\n",
      "ENTRAÎNEMENT DU MODÈLE\n",
      "======================================================================\n",
      "Epoch 1/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.0644 - auc: 0.5111 - loss: 0.7909 - precision: 0.5070 - recall: 0.4356"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 317\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mENTRAÎNEMENT DU MODÈLE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    315\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m history_bert = \u001b[43mmodel_bert\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdev_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Augmenter pour de meilleurs résultats\u001b[39;49;00m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks_bert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    323\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✓ Entraînement terminé!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    328\u001b[39m \u001b[38;5;66;03m# --- 11. ÉVALUATION ---\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:423\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_eval_epoch_iterator\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    413\u001b[39m     \u001b[38;5;28mself\u001b[39m._eval_epoch_iterator = TFEpochIterator(\n\u001b[32m    414\u001b[39m         x=val_x,\n\u001b[32m    415\u001b[39m         y=val_y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    421\u001b[39m         shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    422\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m val_logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    433\u001b[39m val_logs = {\n\u001b[32m    434\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mval_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs.items()\n\u001b[32m    435\u001b[39m }\n\u001b[32m    436\u001b[39m epoch_logs.update(val_logs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:511\u001b[39m, in \u001b[36mTensorFlowTrainer.evaluate\u001b[39m\u001b[34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[39m\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    510\u001b[39m     callbacks.on_test_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m     callbacks.on_test_batch_end(end_step, logs)\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_evaluating:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:889\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    887\u001b[39m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[32m    888\u001b[39m   initializers = []\n\u001b[32m--> \u001b[39m\u001b[32m889\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    891\u001b[39m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[32m    892\u001b[39m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[32m    893\u001b[39m   \u001b[38;5;28mself\u001b[39m._lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:696\u001b[39m, in \u001b[36mFunction._initialize\u001b[39m\u001b[34m(self, args, kwds, add_initializers_to)\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28mself\u001b[39m._variable_creation_config = \u001b[38;5;28mself\u001b[39m._generate_scoped_tracing_options(\n\u001b[32m    692\u001b[39m     variable_capturing_scope,\n\u001b[32m    693\u001b[39m     tracing_compilation.ScopeType.VARIABLE_CREATION,\n\u001b[32m    694\u001b[39m )\n\u001b[32m    695\u001b[39m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvalid_creator_scope\u001b[39m(*unused_args, **unused_kwds):\n\u001b[32m    701\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m   target_func_type = lookup_func_type\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m concrete_function = \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    288\u001b[39m   tracing_options.function_cache.add(\n\u001b[32m    289\u001b[39m       concrete_function, current_func_context\n\u001b[32m    290\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[39m, in \u001b[36m_create_concrete_function\u001b[39m\u001b[34m(function_type, type_context, func_graph, tracing_options)\u001b[39m\n\u001b[32m    303\u001b[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001b[32m    304\u001b[39m       placeholder_context\n\u001b[32m    305\u001b[39m   )\n\u001b[32m    307\u001b[39m disable_acd = tracing_options.attributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options.attributes.get(\n\u001b[32m    308\u001b[39m     attributes_lib.DISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    309\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m traced_func_graph = \u001b[43mfunc_graph_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_type_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001b[32m    324\u001b[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1060\u001b[39m, in \u001b[36mfunc_graph_from_py_func\u001b[39m\u001b[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[39m\n\u001b[32m   1057\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m   1059\u001b[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m func_outputs = \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[32m   1064\u001b[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:599\u001b[39m, in \u001b[36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m default_graph._variable_creator_scope(scope, priority=\u001b[32m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    596\u001b[39m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[32m    597\u001b[39m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[32m    598\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     out = \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:41\u001b[39m, in \u001b[36mpy_func_from_autograph.<locals>.autograph_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m     51\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mag_error_metadata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:339\u001b[39m, in \u001b[36mconverted_call\u001b[39m\u001b[34m(f, args, kwargs, caller_fn_scope, options)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_autograph_artifact(f):\n\u001b[32m    338\u001b[39m   logging.log(\u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPermanently allowed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: AutoGraph artifact\u001b[39m\u001b[33m'\u001b[39m, f)\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;66;03m# If this is a partial, unwrap it and redo all the checks.\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, functools.partial):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[39m, in \u001b[36m_call_unconverted\u001b[39m\u001b[34m(f, args, kwargs, options, update_cache)\u001b[39m\n\u001b[32m    456\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m f.\u001b[34m__self__\u001b[39m.call(args, kwargs)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m f(*args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:154\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.multi_step_on_iterator\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;129m@tf\u001b[39m.autograph.experimental.do_not_convert\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmulti_step_on_iterator\u001b[39m(iterator):\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps_per_execution == \u001b[32m1\u001b[39m:\n\u001b[32m    153\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tf.experimental.Optional.from_value(\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m             \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m         )\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# the spec is set lazily during the tracing of `tf.while_loop`\u001b[39;00m\n\u001b[32m    158\u001b[39m     empty_outputs = tf.experimental.Optional.empty(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:125\u001b[39m, in \u001b[36mTensorFlowTrainer._autoconvert_optionals.<locals>.wrapper\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(step_func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(data):\n\u001b[32m    119\u001b[39m     converted_data = tree.map_structure(\n\u001b[32m    120\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m i: (\n\u001b[32m    121\u001b[39m             \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, tf.experimental.Optional) \u001b[38;5;28;01melse\u001b[39;00m i\n\u001b[32m    122\u001b[39m         ),\n\u001b[32m    123\u001b[39m         data,\n\u001b[32m    124\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     result = \u001b[43mstep_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:889\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    887\u001b[39m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[32m    888\u001b[39m   initializers = []\n\u001b[32m--> \u001b[39m\u001b[32m889\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    891\u001b[39m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[32m    892\u001b[39m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[32m    893\u001b[39m   \u001b[38;5;28mself\u001b[39m._lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:696\u001b[39m, in \u001b[36mFunction._initialize\u001b[39m\u001b[34m(self, args, kwds, add_initializers_to)\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28mself\u001b[39m._variable_creation_config = \u001b[38;5;28mself\u001b[39m._generate_scoped_tracing_options(\n\u001b[32m    692\u001b[39m     variable_capturing_scope,\n\u001b[32m    693\u001b[39m     tracing_compilation.ScopeType.VARIABLE_CREATION,\n\u001b[32m    694\u001b[39m )\n\u001b[32m    695\u001b[39m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvalid_creator_scope\u001b[39m(*unused_args, **unused_kwds):\n\u001b[32m    701\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m   target_func_type = lookup_func_type\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m concrete_function = \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    288\u001b[39m   tracing_options.function_cache.add(\n\u001b[32m    289\u001b[39m       concrete_function, current_func_context\n\u001b[32m    290\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[39m, in \u001b[36m_create_concrete_function\u001b[39m\u001b[34m(function_type, type_context, func_graph, tracing_options)\u001b[39m\n\u001b[32m    303\u001b[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001b[32m    304\u001b[39m       placeholder_context\n\u001b[32m    305\u001b[39m   )\n\u001b[32m    307\u001b[39m disable_acd = tracing_options.attributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options.attributes.get(\n\u001b[32m    308\u001b[39m     attributes_lib.DISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    309\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m traced_func_graph = \u001b[43mfunc_graph_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_type_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001b[32m    324\u001b[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1060\u001b[39m, in \u001b[36mfunc_graph_from_py_func\u001b[39m\u001b[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[39m\n\u001b[32m   1057\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m   1059\u001b[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m func_outputs = \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[32m   1064\u001b[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:599\u001b[39m, in \u001b[36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m default_graph._variable_creator_scope(scope, priority=\u001b[32m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    596\u001b[39m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[32m    597\u001b[39m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[32m    598\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     out = \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:41\u001b[39m, in \u001b[36mpy_func_from_autograph.<locals>.autograph_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m     51\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mag_error_metadata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:339\u001b[39m, in \u001b[36mconverted_call\u001b[39m\u001b[34m(f, args, kwargs, caller_fn_scope, options)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_autograph_artifact(f):\n\u001b[32m    338\u001b[39m   logging.log(\u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPermanently allowed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: AutoGraph artifact\u001b[39m\u001b[33m'\u001b[39m, f)\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;66;03m# If this is a partial, unwrap it and redo all the checks.\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, functools.partial):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[39m, in \u001b[36m_call_unconverted\u001b[39m\u001b[34m(f, args, kwargs, options, update_cache)\u001b[39m\n\u001b[32m    456\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m f.\u001b[34m__self__\u001b[39m.call(args, kwargs)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m f(*args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:134\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.one_step_on_data\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;129m@tf\u001b[39m.autograph.experimental.do_not_convert\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mone_step_on_data\u001b[39m(data):\n\u001b[32m    133\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m     outputs = reduce_per_replica(\n\u001b[32m    136\u001b[39m         outputs,\n\u001b[32m    137\u001b[39m         \u001b[38;5;28mself\u001b[39m.distribute_strategy,\n\u001b[32m    138\u001b[39m         reduction=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1673\u001b[39m, in \u001b[36mStrategyBase.run\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1668\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scope():\n\u001b[32m   1669\u001b[39m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[32m   1670\u001b[39m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[32m   1671\u001b[39m   fn = autograph.tf_convert(\n\u001b[32m   1672\u001b[39m       fn, autograph_ctx.control_status_ctx(), convert_by_default=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1673\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extended\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3263\u001b[39m, in \u001b[36mStrategyExtendedV1.call_for_each_replica\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   3261\u001b[39m   kwargs = {}\n\u001b[32m   3262\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._container_strategy().scope():\n\u001b[32m-> \u001b[39m\u001b[32m3263\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4061\u001b[39m, in \u001b[36m_DefaultDistributionExtended._call_for_each_replica\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   4059\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[32m   4060\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m._container_strategy(), replica_id_in_sync_group=\u001b[32m0\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4061\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:93\u001b[39m, in \u001b[36mTensorFlowTrainer.test_step\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     91\u001b[39m x, y, sample_weight = data_adapter_utils.unpack_x_y_sample_weight(data)\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_has_training_arg:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     y_pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     95\u001b[39m     y_pred = \u001b[38;5;28mself\u001b[39m(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36mBERTMultiLabelClassifier.call\u001b[39m\u001b[34m(self, inputs, training)\u001b[39m\n\u001b[32m     74\u001b[39m attention_mask = inputs[\u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# ← CLEF: Passer les tensors TensorFlow directement à BERT\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# BERT accepte les TensorFlow tensors, pas les KerasTensors\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m bert_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Utiliser le token [CLS] (pooled output)\u001b[39;00m\n\u001b[32m     85\u001b[39m cls_token = bert_output[\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# Shape: (batch_size, 768)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:65\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py:588\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    584\u001b[39m         \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(inputs, *copied_args, **copied_kwargs)\n\u001b[32m    586\u001b[39m     layout_map_lib._map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m._layout_map)\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:65\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py:1155\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1150\u001b[39m     inputs = \u001b[38;5;28mself\u001b[39m._maybe_cast_inputs(inputs, input_list)\n\u001b[32m   1152\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable.enable_auto_cast_variables(\n\u001b[32m   1153\u001b[39m     \u001b[38;5;28mself\u001b[39m._compute_dtype_object\n\u001b[32m   1154\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1155\u001b[39m     outputs = \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._activity_regularizer:\n\u001b[32m   1158\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle_activity_regularization(inputs, outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:96\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     99\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:437\u001b[39m, in \u001b[36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    434\u001b[39m     config = \u001b[38;5;28mself\u001b[39m.config\n\u001b[32m    436\u001b[39m unpacked_inputs = input_processing(func, config, **fn_args_and_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:1208\u001b[39m, in \u001b[36mTFBertModel.call\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;129m@unpack_inputs\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;129m@add_start_docstrings_to_model_forward\u001b[39m(BERT_INPUTS_DOCSTRING.format(\u001b[33m\"\u001b[39m\u001b[33mbatch_size, sequence_length\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1166\u001b[39m \u001b[38;5;129m@add_code_sample_docstrings\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1186\u001b[39m     training: \u001b[38;5;28mbool\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1187\u001b[39m ) -> TFBaseModelOutputWithPoolingAndCrossAttentions | \u001b[38;5;28mtuple\u001b[39m[tf.Tensor]:\n\u001b[32m   1188\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1189\u001b[39m \u001b[33;03m    encoder_hidden_states  (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\u001b[39;00m\n\u001b[32m   1190\u001b[39m \u001b[33;03m        Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1206\u001b[39m \u001b[33;03m        `past_key_values`). Set to `False` during training, `True` during generation\u001b[39;00m\n\u001b[32m   1207\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1208\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:65\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py:1155\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1150\u001b[39m     inputs = \u001b[38;5;28mself\u001b[39m._maybe_cast_inputs(inputs, input_list)\n\u001b[32m   1152\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable.enable_auto_cast_variables(\n\u001b[32m   1153\u001b[39m     \u001b[38;5;28mself\u001b[39m._compute_dtype_object\n\u001b[32m   1154\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1155\u001b[39m     outputs = \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._activity_regularizer:\n\u001b[32m   1158\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle_activity_regularization(inputs, outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:96\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     99\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:437\u001b[39m, in \u001b[36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    434\u001b[39m     config = \u001b[38;5;28mself\u001b[39m.config\n\u001b[32m    436\u001b[39m unpacked_inputs = input_processing(func, config, **fn_args_and_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:968\u001b[39m, in \u001b[36mTFBertMainLayer.call\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[39m\n\u001b[32m    965\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    966\u001b[39m     head_mask = [\u001b[38;5;28;01mNone\u001b[39;00m] * \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers\n\u001b[32m--> \u001b[39m\u001b[32m968\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    983\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(hidden_states=sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:65\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py:1155\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1150\u001b[39m     inputs = \u001b[38;5;28mself\u001b[39m._maybe_cast_inputs(inputs, input_list)\n\u001b[32m   1152\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable.enable_auto_cast_variables(\n\u001b[32m   1153\u001b[39m     \u001b[38;5;28mself\u001b[39m._compute_dtype_object\n\u001b[32m   1154\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1155\u001b[39m     outputs = \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._activity_regularizer:\n\u001b[32m   1158\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle_activity_regularization(inputs, outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:96\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     99\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:608\u001b[39m, in \u001b[36mTFBertEncoder.call\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[39m\n\u001b[32m    604\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m    606\u001b[39m past_key_value = past_key_values[i] \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m608\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    618\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:65\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py:1155\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1150\u001b[39m     inputs = \u001b[38;5;28mself\u001b[39m._maybe_cast_inputs(inputs, input_list)\n\u001b[32m   1152\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable.enable_auto_cast_variables(\n\u001b[32m   1153\u001b[39m     \u001b[38;5;28mself\u001b[39m._compute_dtype_object\n\u001b[32m   1154\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1155\u001b[39m     outputs = \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._activity_regularizer:\n\u001b[32m   1158\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle_activity_regularization(inputs, outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:96\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     99\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:547\u001b[39m, in \u001b[36mTFBertLayer.call\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001b[39m\n\u001b[32m    544\u001b[39m     cross_attn_present_key_value = cross_attention_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    545\u001b[39m     present_key_value = present_key_value + cross_attn_present_key_value\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m intermediate_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    548\u001b[39m layer_output = \u001b[38;5;28mself\u001b[39m.bert_output(\n\u001b[32m    549\u001b[39m     hidden_states=intermediate_output, input_tensor=attention_output, training=training\n\u001b[32m    550\u001b[39m )\n\u001b[32m    551\u001b[39m outputs = (layer_output,) + outputs  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:65\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py:1155\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1150\u001b[39m     inputs = \u001b[38;5;28mself\u001b[39m._maybe_cast_inputs(inputs, input_list)\n\u001b[32m   1152\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable.enable_auto_cast_variables(\n\u001b[32m   1153\u001b[39m     \u001b[38;5;28mself\u001b[39m._compute_dtype_object\n\u001b[32m   1154\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1155\u001b[39m     outputs = \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._activity_regularizer:\n\u001b[32m   1158\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle_activity_regularization(inputs, outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:96\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     99\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:430\u001b[39m, in \u001b[36mTFBertIntermediate.call\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: tf.Tensor) -> tf.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.intermediate_act_fn(hidden_states)\n\u001b[32m    433\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:65\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py:1155\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1150\u001b[39m     inputs = \u001b[38;5;28mself\u001b[39m._maybe_cast_inputs(inputs, input_list)\n\u001b[32m   1152\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable.enable_auto_cast_variables(\n\u001b[32m   1153\u001b[39m     \u001b[38;5;28mself\u001b[39m._compute_dtype_object\n\u001b[32m   1154\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1155\u001b[39m     outputs = \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._activity_regularizer:\n\u001b[32m   1158\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle_activity_regularization(inputs, outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:96\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     99\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tf_keras\\src\\layers\\core\\dense.py:244\u001b[39m, in \u001b[36mDense.call\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    241\u001b[39m         outputs = tf.matmul(a=inputs, b=\u001b[38;5;28mself\u001b[39m.kernel)\n\u001b[32m    242\u001b[39m \u001b[38;5;66;03m# Broadcast kernel to inputs.\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     outputs = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensordot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;66;03m# Reshape the output back to the original ndim of the input.\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf.executing_eagerly():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1264\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1266\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1267\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1268\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:5408\u001b[39m, in \u001b[36mtensordot\u001b[39m\u001b[34m(a, b, axes, name)\u001b[39m\n\u001b[32m   5406\u001b[39m b = ops.convert_to_tensor(b, name=\u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   5407\u001b[39m a_axes, b_axes = _tensordot_axes(a, axes)\n\u001b[32m-> \u001b[39m\u001b[32m5408\u001b[39m a_reshape, a_free_dims, a_free_dims_static = \u001b[43m_tensordot_reshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5409\u001b[39m b_reshape, b_free_dims, b_free_dims_static = _tensordot_reshape(\n\u001b[32m   5410\u001b[39m     b, b_axes, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   5411\u001b[39m ab_matmul = matmul(a_reshape, b_reshape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:5359\u001b[39m, in \u001b[36mtensordot.<locals>._tensordot_reshape\u001b[39m\u001b[34m(a, axes, flipped)\u001b[39m\n\u001b[32m   5357\u001b[39m axes_dims = array_ops.gather(shape_a, axes)\n\u001b[32m   5358\u001b[39m prod_free_dims = reduce_prod(free_dims)\n\u001b[32m-> \u001b[39m\u001b[32m5359\u001b[39m prod_axes_dims = \u001b[43mreduce_prod\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxes_dims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5360\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flipped:\n\u001b[32m   5361\u001b[39m   perm = array_ops.concat([axes, free], \u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:88\u001b[39m, in \u001b[36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     87\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m     90\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1264\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1266\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1267\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1268\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:2758\u001b[39m, in \u001b[36mreduce_prod\u001b[39m\u001b[34m(input_tensor, axis, keepdims, name)\u001b[39m\n\u001b[32m   2716\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Computes `tf.math.multiply` of elements across dimensions of a tensor.\u001b[39;00m\n\u001b[32m   2717\u001b[39m \n\u001b[32m   2718\u001b[39m \u001b[33;03mThis is the reduction operation for the elementwise `tf.math.multiply` op.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2752\u001b[39m \u001b[33;03m@end_compatibility\u001b[39;00m\n\u001b[32m   2753\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2754\u001b[39m keepdims = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(keepdims)\n\u001b[32m   2755\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _may_reduce_to_scalar(\n\u001b[32m   2756\u001b[39m     keepdims, axis,\n\u001b[32m   2757\u001b[39m     gen_math_ops.prod(\n\u001b[32m-> \u001b[39m\u001b[32m2758\u001b[39m         input_tensor, \u001b[43m_ReductionDims\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m, keepdims,\n\u001b[32m   2759\u001b[39m         name=name))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:2096\u001b[39m, in \u001b[36m_ReductionDims\u001b[39m\u001b[34m(x, axis)\u001b[39m\n\u001b[32m   2094\u001b[39m \u001b[38;5;66;03m# Fast path: avoid creating Rank and Range ops if ndims is known.\u001b[39;00m\n\u001b[32m   2095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x_rank:\n\u001b[32m-> \u001b[39m\u001b[32m2096\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_rank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2097\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2098\u001b[39m   \u001b[38;5;66;03m# Otherwise, we rely on Range and Rank to do the right thing at run-time.\u001b[39;00m\n\u001b[32m   2099\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, array_ops.rank(x))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:142\u001b[39m, in \u001b[36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    141\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m    144\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:276\u001b[39m, in \u001b[36mconstant\u001b[39m\u001b[34m(value, dtype, shape, name)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m\"\u001b[39m, v1=[])\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconstant\u001b[39m(\n\u001b[32m    179\u001b[39m     value, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, shape=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[33m\"\u001b[39m\u001b[33mConst\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m ) -> Union[ops.Operation, ops._EagerTensorBase]:\n\u001b[32m    181\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[32m    182\u001b[39m \n\u001b[32m    183\u001b[39m \u001b[33;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m \u001b[33;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:291\u001b[39m, in \u001b[36m_constant_impl\u001b[39m\u001b[34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[39m\n\u001b[32m    288\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[32m    289\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m const_tensor = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_graph_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    292\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_broadcast\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:289\u001b[39m, in \u001b[36m_create_graph_constant\u001b[39m\u001b[34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[39m\n\u001b[32m    287\u001b[39m dtype_value = attr_value_pb2.AttrValue(\u001b[38;5;28mtype\u001b[39m=tensor_value.tensor.dtype)\n\u001b[32m    288\u001b[39m attrs = {\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m: tensor_value, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m: dtype_value}\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m const_tensor = \u001b[43mg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mConst\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtype_value\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m.outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m op_callbacks.should_invoke_op_callbacks():\n\u001b[32m    293\u001b[39m   \u001b[38;5;66;03m# TODO(b/147670703): Once the special-op creation code paths\u001b[39;00m\n\u001b[32m    294\u001b[39m   \u001b[38;5;66;03m# are unified. Remove this `if` block.\u001b[39;00m\n\u001b[32m    295\u001b[39m   callback_outputs = op_callbacks.invoke_op_callbacks(\n\u001b[32m    296\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mConst\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mtuple\u001b[39m(), attrs, (const_tensor,), op_name=name, graph=g)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:614\u001b[39m, in \u001b[36mFuncGraph._create_op_internal\u001b[39m\u001b[34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[39m\n\u001b[32m    612\u001b[39m   inp = \u001b[38;5;28mself\u001b[39m.capture(inp)\n\u001b[32m    613\u001b[39m   captured_inputs.append(inp)\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2726\u001b[39m, in \u001b[36mGraph._create_op_internal\u001b[39m\u001b[34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[39m\n\u001b[32m   2723\u001b[39m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[32m   2724\u001b[39m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[32m   2725\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mutation_lock():\n\u001b[32m-> \u001b[39m\u001b[32m2726\u001b[39m   ret = \u001b[43mOperation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_node_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2734\u001b[39m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m=\u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2735\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2736\u001b[39m   \u001b[38;5;28mself\u001b[39m._create_op_helper(ret, compute_device=compute_device)\n\u001b[32m   2737\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1221\u001b[39m, in \u001b[36mOperation.from_node_def\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1218\u001b[39m     control_input_ops.append(control_op)\n\u001b[32m   1220\u001b[39m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m c_op = \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m=\u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[38;5;28mself\u001b[39m = Operation(c_op, SymbolicTensor)\n\u001b[32m   1223\u001b[39m \u001b[38;5;28mself\u001b[39m._init(g)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yosrb\\Downloads\\GOEMOTION\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1078\u001b[39m, in \u001b[36m_create_c_op\u001b[39m\u001b[34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[39m\n\u001b[32m   1074\u001b[39m   pywrap_tf_session.TF_SetAttrValueProto(op_desc, compat.as_str(name),\n\u001b[32m   1075\u001b[39m                                          serialized)\n\u001b[32m   1077\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m   c_op = \u001b[43mpywrap_tf_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTF_FinishOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_desc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m errors.InvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1080\u001b[39m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[32m   1081\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e.message)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ========================================================================== #\n",
    "# MODÈLE 4: BERT-BASE TRANSFORMER (Fine-tuning) - FIX SUBCLASSING API\n",
    "# ========================================================================== #\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODÈLE 4: BERT-BASE POUR CLASSIFICATION MULTI-LABEL\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Version Transformers: {transformers.__version__}\")\n",
    "print(f\"Version TensorFlow: {tf.__version__}\")\n",
    "\n",
    "# --- 1. CHARGEMENT DU TOKENIZER ET MODÈLE BERT ---\n",
    "print(\"\\nChargement du tokenizer BERT...\")\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "print(\"✓ Tokenizer chargé\")\n",
    "\n",
    "\n",
    "# --- 2. CONSTRUCTION DU MODÈLE - SUBCLASSING API (PAS FUNCTIONAL) ---\n",
    "class BERTMultiLabelClassifier(Model):\n",
    "    \"\"\"\n",
    "    Modèle BERT pour classification multi-label utilisant Subclassing API.\n",
    "    \n",
    "    Contrairement à la Functional API, le Subclassing API permet de passer\n",
    "    directement les KerasTensors à BERT sans problème de conversion.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_labels=28, bert_model_name='bert-base-uncased', **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_labels: Nombre de classes (28 émotions)\n",
    "            bert_model_name: Nom du modèle BERT pré-entraîné\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Charger le modèle BERT pré-entraîné\n",
    "        print(f\"\\nChargement du modèle BERT {bert_model_name}...\")\n",
    "        self.bert = TFBertModel.from_pretrained(\n",
    "            bert_model_name,\n",
    "            use_safetensors=False  # Fix pour safetensors\n",
    "        )\n",
    "        print(\"✓ BERT chargé\")\n",
    "        \n",
    "        # Couches de classification\n",
    "        self.dropout_bert = Dropout(0.3)\n",
    "        self.dense_1 = Dense(256, activation='relu', name='dense_1')\n",
    "        self.dropout_1 = Dropout(0.3)\n",
    "        self.dense_2 = Dense(128, activation='relu', name='dense_2')\n",
    "        self.dropout_2 = Dropout(0.3)\n",
    "        self.output_layer = Dense(num_labels, activation='sigmoid', name='output')\n",
    "        \n",
    "        self.num_labels = num_labels\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"\n",
    "        Forward pass du modèle.\n",
    "        \n",
    "        Args:\n",
    "            inputs: Dict avec 'input_ids' et 'attention_mask'\n",
    "            training: Booléen pour dropout\n",
    "        \n",
    "        Returns:\n",
    "            Tensor de probabilités (batch_size, num_labels)\n",
    "        \"\"\"\n",
    "        # Extraire les inputs\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        \n",
    "        # ← CLEF: Passer les tensors TensorFlow directement à BERT\n",
    "        # BERT accepte les TensorFlow tensors, pas les KerasTensors\n",
    "        bert_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            training=training\n",
    "        )\n",
    "        \n",
    "        # Utiliser le token [CLS] (pooled output)\n",
    "        cls_token = bert_output[1]  # Shape: (batch_size, 768)\n",
    "        \n",
    "        # Classification layers\n",
    "        x = self.dropout_bert(cls_token, training=training)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dropout_1(x, training=training)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.dropout_2(x, training=training)\n",
    "        output = self.output_layer(x)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"Pour pouvoir sauvegarder et charger le modèle\"\"\"\n",
    "        return {\n",
    "            'num_labels': self.num_labels,\n",
    "            'bert_model_name': 'bert-base-uncased'\n",
    "        }\n",
    "\n",
    "\n",
    "# --- 3. CRÉER UNE INSTANCE DU MODÈLE ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONSTRUCTION DU MODÈLE BERT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "NUM_LABELS = 28\n",
    "MAX_LENGTH_BERT = 128\n",
    "\n",
    "model_bert = BERTMultiLabelClassifier(\n",
    "    num_labels=NUM_LABELS,\n",
    "    bert_model_name='bert-base-uncased',\n",
    "    name='BERT_MultiLabel_Classifier'\n",
    ")\n",
    "\n",
    "print(\"✓ Modèle créé avec succès!\")\n",
    "\n",
    "\n",
    "# --- 4. COMPILATION DU MODÈLE ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPILATION DU MODÈLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def custom_loss_function(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Weighted Binary Cross-Entropy pour multi-label.\n",
    "    \"\"\"\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "    bce = -y_true * tf.math.log(y_pred) - (1 - y_true) * tf.math.log(1 - y_pred)\n",
    "    return tf.reduce_mean(bce)\n",
    "\n",
    "model_bert.compile(\n",
    "    optimizer=Adam(learning_rate=2e-5),\n",
    "    loss=custom_loss_function,\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc', multi_label=True),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"✓ Modèle compilé avec succès\")\n",
    "print(\"  - Optimizer: Adam (lr=2e-5)\")\n",
    "print(\"  - Loss: Weighted Binary Cross-Entropy\")\n",
    "print(\"  - Metrics: AUC, Precision, Recall\")\n",
    "\n",
    "\n",
    "# --- 5. RÉSUMÉ DE L'ARCHITECTURE ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ARCHITECTURE DU MODÈLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Build the model by calling it once\n",
    "dummy_input = {\n",
    "    'input_ids': tf.zeros((1, MAX_LENGTH_BERT), dtype=tf.int32),\n",
    "    'attention_mask': tf.ones((1, MAX_LENGTH_BERT), dtype=tf.int32)\n",
    "}\n",
    "_ = model_bert(dummy_input, training=False)\n",
    "\n",
    "print(model_bert.summary())\n",
    "\n",
    "\n",
    "# --- 6. FONCTION DE TOKENIZATION ---\n",
    "def encode_texts_for_bert(texts, tokenizer, max_length=128):\n",
    "    \"\"\"\n",
    "    Tokenise les textes au format BERT.\n",
    "    \n",
    "    Args:\n",
    "        texts: Liste de textes\n",
    "        tokenizer: BertTokenizer\n",
    "        max_length: Longueur maximale\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (input_ids, attention_mask) comme numpy arrays\n",
    "    \"\"\"\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for text in texts:\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "        \n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=None  # Pas de tensors\n",
    "        )\n",
    "        \n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    \n",
    "    return np.array(input_ids), np.array(attention_masks)\n",
    "\n",
    "\n",
    "# --- 7. CRÉER LES DATASETS ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PRÉPARATION DES DONNÉES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Créer des données fictices pour démonstration\n",
    "np.random.seed(42)\n",
    "n_samples_train = 100\n",
    "n_samples_dev = 20\n",
    "n_samples_test = 20\n",
    "\n",
    "# Textes\n",
    "texts_train = [f\"This is sample text number {i} for training\" for i in range(n_samples_train)]\n",
    "texts_dev = [f\"This is sample text number {i} for development\" for i in range(n_samples_dev)]\n",
    "texts_test = [f\"This is sample text number {i} for testing\" for i in range(n_samples_test)]\n",
    "\n",
    "# Labels multi-label\n",
    "y_train = np.random.randint(0, 2, size=(n_samples_train, NUM_LABELS)).astype(np.float32)\n",
    "y_dev = np.random.randint(0, 2, size=(n_samples_dev, NUM_LABELS)).astype(np.float32)\n",
    "y_test = np.random.randint(0, 2, size=(n_samples_test, NUM_LABELS)).astype(np.float32)\n",
    "\n",
    "print(\"\\nTokenisation des données...\")\n",
    "train_input_ids, train_attention_mask = encode_texts_for_bert(texts_train, bert_tokenizer, MAX_LENGTH_BERT)\n",
    "dev_input_ids, dev_attention_mask = encode_texts_for_bert(texts_dev, bert_tokenizer, MAX_LENGTH_BERT)\n",
    "test_input_ids, test_attention_mask = encode_texts_for_bert(texts_test, bert_tokenizer, MAX_LENGTH_BERT)\n",
    "\n",
    "print(f\"✓ input_ids shape: {train_input_ids.shape}\")\n",
    "print(f\"✓ attention_mask shape: {train_attention_mask.shape}\")\n",
    "print(f\"✓ labels shape: {y_train.shape}\")\n",
    "\n",
    "# Créer les datasets TensorFlow\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "def create_dataset(input_ids, attention_mask, labels, batch_size=32, shuffle=True):\n",
    "    \"\"\"Crée un tf.data.Dataset.\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        },\n",
    "        labels\n",
    "    ))\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(labels), reshuffle_each_iteration=True)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "train_dataset = create_dataset(train_input_ids, train_attention_mask, y_train, BATCH_SIZE)\n",
    "dev_dataset = create_dataset(dev_input_ids, dev_attention_mask, y_dev, BATCH_SIZE, shuffle=False)\n",
    "test_dataset = create_dataset(test_input_ids, test_attention_mask, y_test, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"\\n✓ Train dataset: {len(train_dataset)} batches\")\n",
    "print(f\"✓ Dev dataset: {len(dev_dataset)} batches\")\n",
    "print(f\"✓ Test dataset: {len(test_dataset)} batches\")\n",
    "\n",
    "\n",
    "# --- 8. TEST FORWARD PASS AVANT ENTRAÎNEMENT ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST FORWARD PASS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nFaisant une prédiction de test...\")\n",
    "sample_batch = next(iter(train_dataset))\n",
    "sample_input, sample_label = sample_batch\n",
    "\n",
    "try:\n",
    "    prediction = model_bert(sample_input, training=False)\n",
    "    print(f\"✓ Forward pass réussi!\")\n",
    "    print(f\"  Input shape: {sample_input['input_ids'].shape}\")\n",
    "    print(f\"  Output shape: {prediction.shape}\")\n",
    "    print(f\"  Output range: [{prediction.numpy().min():.4f}, {prediction.numpy().max():.4f}]\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Erreur lors du forward pass: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# --- 9. CALLBACKS POUR L'ENTRAÎNEMENT ---\n",
    "import os\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "callbacks_bert = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_auc',\n",
    "        patience=3,\n",
    "        mode='max',\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/modele_bert_best.keras',\n",
    "        monitor='val_auc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "# --- 10. ENTRAÎNEMENT ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENTRAÎNEMENT DU MODÈLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "history_bert = model_bert.fit(\n",
    "    train_dataset,\n",
    "    validation_data=dev_dataset,\n",
    "    epochs=5,  # Augmenter pour de meilleurs résultats\n",
    "    callbacks=callbacks_bert,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Entraînement terminé!\")\n",
    "\n",
    "\n",
    "# --- 11. ÉVALUATION ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ÉVALUATION SUR L'ENSEMBLE DE TEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_results = model_bert.evaluate(test_dataset, verbose=1)\n",
    "print(f\"\\nRésultats de test:\")\n",
    "print(f\"  Loss: {test_results[0]:.4f}\")\n",
    "print(f\"  Accuracy: {test_results[1]:.4f}\")\n",
    "print(f\"  AUC: {test_results[2]:.4f}\")\n",
    "print(f\"  Precision: {test_results[3]:.4f}\")\n",
    "print(f\"  Recall: {test_results[4]:.4f}\")\n",
    "\n",
    "\n",
    "# --- 12. SAUVEGARDE ET CHARGEMENT ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAUVEGARDE DU MODÈLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "model_bert.save('models/bert_model_final.keras')\n",
    "print(\"✓ Modèle sauvegardé: models/bert_model_final.keras\")\n",
    "\n",
    "# Sauvegarder le tokenizer\n",
    "bert_tokenizer.save_pretrained('models/bert_tokenizer')\n",
    "print(\"✓ Tokenizer sauvegardé: models/bert_tokenizer\")\n",
    "\n",
    "\n",
    "# --- 13. PRÉDICTIONS SUR NOUVEAUX TEXTES ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PRÉDICTIONS SUR NOUVEAUX TEXTES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def predict_emotions(texts, model, tokenizer, max_length=128, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Prédit les émotions pour une liste de textes.\n",
    "    \n",
    "    Args:\n",
    "        texts: Liste de textes\n",
    "        model: Modèle entraîné\n",
    "        tokenizer: Tokenizer BERT\n",
    "        max_length: Longueur maximale\n",
    "        threshold: Seuil de prédiction\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (probabilités, prédictions binaires)\n",
    "    \"\"\"\n",
    "    input_ids, attention_mask = encode_texts_for_bert(texts, tokenizer, max_length)\n",
    "    \n",
    "    # Créer un dataset avec batch_size = nombre de textes\n",
    "    dataset = tf.data.Dataset.from_tensor_slices({\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask\n",
    "    }).batch(len(texts))\n",
    "    \n",
    "    # Faire les prédictions\n",
    "    batch = next(iter(dataset))\n",
    "    predictions = model(batch, training=False)\n",
    "    \n",
    "    # Appliquer le threshold\n",
    "    binary_predictions = (predictions.numpy() > threshold).astype(int)\n",
    "    \n",
    "    return predictions.numpy(), binary_predictions\n",
    "\n",
    "# Exemple de prédiction\n",
    "test_texts = [\n",
    "    \"I love this movie! It's amazing and beautiful.\",\n",
    "    \"This is terrible and makes me very sad.\",\n",
    "    \"I am not sure about this situation.\"\n",
    "]\n",
    "\n",
    "print(\"\\nTextes de test:\")\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    print(f\"  {i}. {text}\")\n",
    "\n",
    "probs, binary_preds = predict_emotions(test_texts, model_bert, bert_tokenizer)\n",
    "\n",
    "print(f\"\\nProbabilités prédites shape: {probs.shape}\")\n",
    "print(f\"Prédictions binaires shape: {binary_preds.shape}\")\n",
    "print(\"\\nExemple de prédictions (5 premières émotions):\")\n",
    "for i, text in enumerate(test_texts):\n",
    "    print(f\"\\nTexte {i+1}: {text}\")\n",
    "    print(f\"  Probabilités: {probs[i][:5]}\")\n",
    "    print(f\"  Prédictions: {binary_preds[i][:5]}\")\n",
    "\n",
    "\n",
    "# --- 14. CHARGER LE MODÈLE SAUVEGARDÉ ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CHARGEMENT DU MODÈLE SAUVEGARDÉ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nChargement du modèle depuis le disque...\")\n",
    "try:\n",
    "    # Charger le modèle\n",
    "    loaded_model = tf.keras.models.load_model('models/bert_model_final.keras')\n",
    "    print(\"✓ Modèle chargé avec succès!\")\n",
    "    \n",
    "    # Charger le tokenizer\n",
    "    loaded_tokenizer = BertTokenizer.from_pretrained('models/bert_tokenizer')\n",
    "    print(\"✓ Tokenizer chargé avec succès!\")\n",
    "    \n",
    "    # Tester une prédiction\n",
    "    test_text = [\"Hello, this is a test!\"]\n",
    "    probs_loaded, _ = predict_emotions(test_text, loaded_model, loaded_tokenizer)\n",
    "    print(f\"✓ Prédiction avec modèle chargé réussie!\")\n",
    "    print(f\"  Probabilités: {probs_loaded[0][:5]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Erreur lors du chargement: {str(e)}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FIN DU SCRIPT\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
